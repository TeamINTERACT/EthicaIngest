{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T17:19:38.156873Z",
     "start_time": "2020-10-29T17:19:25.800699Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import subprocess as sub\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "#import seaborn as sns\n",
    "import matplotlib\n",
    "from tabulate import tabulate\n",
    "\n",
    "# tell Seaborn that we're producing a document and not a slideshow or poster\n",
    "#sns.set()\n",
    "#sns.set_context('paper')\n",
    "\n",
    "# expects to find connection credentials in local runtime environment\n",
    "db_host=os.environ['SQL_LOCAL_SERVER']\n",
    "db_host_port=int(os.environ['SQL_LOCAL_PORT'])\n",
    "db_user=os.environ['SQL_USER']\n",
    "db_name=os.environ['SQL_DB']\n",
    "db_schema=os.environ['SQL_SCHEMA']\n",
    "\n",
    "# city-specific parameters\n",
    "wavenumstr = '01'\n",
    "city_num = 4  # vic=1, van=2, ssk=3, mtl=4\n",
    "city_prefix = 'mtl'\n",
    "city_name = 'Montreal'\n",
    "ethica_study_id = [395, 396] #van=376 #vic=212 ssk=448 mtl=395/396\n",
    "datadir = f\"/home/jeffs/projects/def-dfuller/interact/permanent_archive/{city_name}/Wave1/Ethica\"\n",
    "#telemetrydir = f\"{datadir}/{city_name.lower()}_{wavenumstr}/raw\"\n",
    "telemetrydir = f\"{datadir}/{city_name.lower()}_en_{wavenumstr}/raw\"\n",
    "\n",
    "#linkage_file = f\"{datadir}/../INTERACT_Vancouver_ID_Somtam_20190320-flagged.csv\"\n",
    "#linkage_file = f\"{datadir}/../Participant_Tracking_SASK_W1-norm-filtered-redated.csv\"\n",
    "linkage_file = f\"{datadir}/../sensedoc_linkage-normalized.csv\"\n",
    "\n",
    "# Create a list of users who are to be specifically excluded from a particular study\n",
    "# It's being done this way because the linkage CSV files do not encode anything about study numbers, and\n",
    "# adding such a feature would break a lot of code, plus risk contamination of the CSV files through sloppy changes\n",
    "# So since these cases are rare, I'm putting them here, at the head of the code where they should be \n",
    "# obvious and apparent.\n",
    "suppressors = {5904:395}\n",
    "\n",
    "\n",
    "def log(instr):\n",
    "    print(f\"→ {instr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "city_name": "Montreal"
    }
   },
   "source": [
    "# Ingest Log for Ethica Wave 1\n",
    "\n",
    "City: {{city_name}}\n",
    "\n",
    "After much investigation and discussion, we have decided to ingest the data in its raw form, with no filters applied, and then create a few obvious subtables from that ingested data. The reasoning is that, due to the nature of the data issues, there appears to be no single cleaning filter we can apply that will be appropriate for all downstream analysis. So we'll ingest the raw table, mark it as toxic so nobody uses it by accident, and then create a few sane starting points that people can actually use.\n",
    "\n",
    "Building on the work done for the Saskatoon data, this notebook will attempt to parameterize the defining aspects of the ingest, so that the same notebook can be run to ingest all the other cities.\n",
    "\n",
    "## Checklist\n",
    "- Ensure that city-specific params have been set up in code section below\n",
    "- Ensure that any users that are to be re-ingested from linkage have been removed from ethica_assignments table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep\n",
    "Steps to complete before ingesting the telemetry\n",
    "\n",
    "- Verify the integrity of the linkage CSV file before ingesting it\n",
    "- Ingest the linkage CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Linkage CSV\n",
    "This step will assess the CSV file to ensure it's in a parsable format and then confirm that the users listed  match those who have contributed telemetry data. If any errors or mismatches are reported here, the linkage file records should be updated until this verification test passes cleanly.\n",
    "\n",
    "#### Possible problems and their solutions\n",
    "\n",
    "##### User in linkage file but has no telemetry data\n",
    "This can happen when a user was assigned an Ethica account, but either dropped out of the study or switched to SenseDoc before data collection began. If the study coordinator confirms that the user dropped out and produced no usable data, then mark the user with 'ignore' in the data_disposition field of the linkage file. This will exclude them from the list of ids who are expected to have telemetry data.\n",
    "\n",
    "##### User has telemetry data but is not in linkage file\n",
    "This usually happens when data got collected from a staff member who was testing the system. For these people, there *is* data, but we want to remove it from the ingest. So we don't just ignore these records, we have to actively cull the associated data. This is indicated by marking the data_disposition field with 'cull'.\n",
    "\n",
    "**Should the information be placed in the linkage file or the linkage table?** The file is used at ingest validation time, while the table is used at actual telemetry ingest time, so probably both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T17:22:05.586657Z",
     "start_time": "2020-10-29T17:22:05.541469Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions that will be used to verify the linkage CSV file\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "iids = set([])\n",
    "eids = set([])\n",
    "culled_eids = set([])\n",
    "participant_study = {} # a list of which study each participant is registered in\n",
    "\n",
    "# In one city, the linkage encode ethica id as 'Ethica ID'\n",
    "# In another, it is encoded as 'ethica_id'\n",
    "# We may want to make that column name an input parameter\n",
    "\n",
    "def validate_iid(idstr, logfailures=True):\n",
    "    \"\"\"\n",
    "    Given an Interact ID in string form, ensure it's well formed.\n",
    "    Return True if so, False otherwise.\n",
    "    \"\"\"\n",
    "    if not len(idstr.strip()) > 8:\n",
    "        if logfailures: log(f\"Interact ID '{idstr}' is not long enough.\")\n",
    "        return False\n",
    "    try:\n",
    "        iid = int(idstr)\n",
    "    except ValueError:\n",
    "        if logfailures: log(f\"Interact ID '{idstr}' is not an integer.\")\n",
    "        return False\n",
    "    global iids\n",
    "    iids.add(iid)\n",
    "    return True\n",
    "\n",
    "\n",
    "def validate_eid(idstr, logfailures=True):\n",
    "    \"\"\"\n",
    "    Given an Ethica ID in string form, ensure it's well formed and\n",
    "    unique. Return True if so, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        eid = int(idstr)\n",
    "    except ValueError: # filter B\n",
    "        if logfailures: log(f\"Ethica ID '{idstr}' is not an integer.\")\n",
    "        return False\n",
    "    global eids\n",
    "    if eid in eids: # filter A\n",
    "        if logfailures: log(f\"Redundant record for Ethica ID '{idstr}'.\")\n",
    "        return False\n",
    "    eids.add(str(eid)) \n",
    "    # we only converted to int to be sure the string was int-friendly\n",
    "    # all subsequent tests against id will be done as string compares\n",
    "    return True\n",
    "\n",
    "\n",
    "def validate_wear_dates(row):\n",
    "    \"\"\"\n",
    "    Given an Ethica record, ensure it has well-formed start and\n",
    "    end dates. Return True if so, False otherwise.\n",
    "                            DO NOT USE!\n",
    "    Wear dates are only valid for SenseDoc data. With SD, data\n",
    "    capture begins the moment the device is booted, so it captures\n",
    "    activity of the coordinator prior to delivery to the participant,\n",
    "    and then again after the device has been recovered. Wear dates\n",
    "    are used in that situation to filter out the coordinator data.\n",
    "    But Ethica data is different and has no coordinator \"pollution\"\n",
    "    that needs to be removed.\n",
    "\n",
    "    I'm leaving this code here though, with this comment, so that\n",
    "    nobody is tempted to add date filters back in at a later time.\n",
    "    \"\"\"\n",
    "    return True\n",
    "    try:\n",
    "        start_str = row['start_date']\n",
    "        end_str = row['end_date']\n",
    "        start_date = datetime.strptime(start_str,\"%Y-%m-%d\") \n",
    "        end_date = datetime.strptime(end_str,\"%Y-%m-%d\") \n",
    "    except KeyError:\n",
    "        log(f\"EID '{row['ethica_id']}' has missing date field(s)\")\n",
    "        return False\n",
    "    except ValueError:\n",
    "        log(f\"EID '{row['ethica_id']}' has missing/invalid date info {start_str} - {end_str}\")\n",
    "        return False\n",
    "    if start_date >= end_date:\n",
    "        log(f\"EID '{row['ethica_id']}' has invalid date window {start_str} - {end_str}\")\n",
    "        return False\n",
    "    log(f\"EID '{row['ethica_id']}' has good date window {start_str} - {end_str}\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_possible_values_from_csv(filename, colnum):\n",
    "    \"\"\"\n",
    "    Given a CSV file and the name of a column,\n",
    "    return a list of all unique values in that column\n",
    "    \"\"\"\n",
    "    values = set()\n",
    "    # To show a helpul progress bar, we have to know how many\n",
    "    # lines need to be processed, so we need to traverse the file\n",
    "    # twice. This might seem like overkill, but the data files are\n",
    "    # pretty big and can take hours to process. Showing signs of\n",
    "    # life on the console while the script is churning away silently\n",
    "    # in the background can be very reassuring.\n",
    "    log(f\"Scanning file: {filename}\")\n",
    "    #nlines = sum(1 for x in open(filename))\n",
    "    #with open(filename,'r',encoding='ISO-8859-1') as fcsv:\n",
    "    #    reader = csv.DictReader(fcsv,delimiter=',')\n",
    "    #    for row in reader:\n",
    "    #        values.add(row[colname])\n",
    "            \n",
    "    # TURNS OUT THE ABOVE IS HORRIBLY INEFFICIENT\n",
    "    # IT'S ORDERS OF MAGNITUDE FASTER TO RUN A SHELL SCRIPT LIKE THIS:\n",
    "    # cut -d, -f 1 Ethica/montreal_en_01/raw/gps.csv | sort -u\n",
    "    \n",
    "    # set up the piped commands\n",
    "    skipcmd = ['tail', '-n', '+2', filename] # skip the first line, which has column names\n",
    "    listuseridscmd = ['cut', '-d,', '-f', colnum] # user_id = first field of each row\n",
    "    distinctifycmd = ['sort', '-u'] # create a list of distinct ids\n",
    "    \n",
    "    # run the piped commands\n",
    "    p0 = subprocess.Popen(skipcmd, stdout=subprocess.PIPE)\n",
    "    p1 = subprocess.Popen(listuseridscmd, stdin=p0.stdout, stdout=subprocess.PIPE)\n",
    "    p2 = subprocess.Popen(distinctifycmd, stdin=p1.stdout, stdout=subprocess.PIPE, encoding='utf8')\n",
    "    #p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.\n",
    "    output,err = p2.communicate()\n",
    "    \n",
    "    # parse the output\n",
    "    values = []\n",
    "    for val in output.split('\\n'):\n",
    "        if val: # skip empty lines\n",
    "            if val.isnumeric():\n",
    "                values.append(val)\n",
    "            else:\n",
    "                log(f\"Unexpected non-numeric entry in column {colnum} = '{val}'\")\n",
    "\n",
    "    return values\n",
    "\n",
    "# Quick test of the above routine\n",
    "#log(\"Testing function: get_possible_values_from_csv()\")\n",
    "#foo = get_possible_values_from_csv(os.path.join(datadir, 'montreal_en_01/raw/gps.csv'), '1')\n",
    "#log(f\"Found {len(foo)} users in English data.\")\n",
    "#foo = get_possible_values_from_csv(os.path.join(datadir, 'montreal_fr_01/raw/gps.csv'), '1')\n",
    "#log(f\"Found {len(foo)} users in French data.\")\n",
    "\n",
    "def detect_missing_values(master_values, csvfilelist, colnum, colname, streamname):\n",
    "    \"\"\"\n",
    "    Compare the values in a particular column of a CSV against a\n",
    "    master list of expected values and report values in the CSV\n",
    "    that do not match the expectation.\n",
    "    \"\"\"\n",
    "    found_values = set([])\n",
    "    for csvfile in csvfilelist:\n",
    "        studynum = csvfilelist[csvfile]\n",
    "        log(f\"File {csvfile} is associated with study number {studynum}\")\n",
    "        users_in_file = get_possible_values_from_csv(csvfile, colnum)\n",
    "        for user in users_in_file:\n",
    "            if user in participant_study and participant_study[user] != studynum:\n",
    "                log(f\"WARNING: User {user} has data in conflicting studies: {studynum} and {participant_study[user]}\")\n",
    "            participant_study[user] = studynum         \n",
    "        found_values.update(users_in_file)\n",
    "    \n",
    "    #log(f\"Found values: {sorted(list(found_values))}\")\n",
    "    #log(f\"Master values: {sorted(list(master_values))}\")\n",
    "\n",
    "    missing_values = master_values - found_values - culled_eids\n",
    "    log(f\"{len(master_values)} user_ids found in master linkage CSV\")\n",
    "    log(f\"{len(found_values)} distinct ethica_id values found in telemetry CSV data\")\n",
    "    if missing_values: # filter D\n",
    "        log(f\"{len(missing_values)} expected column {colnum} values missing from {streamname} data\")\n",
    "        log(','.join([str(x) for x in sorted(list(missing_values))]))\n",
    "    else:\n",
    "        log(f\"All expected column {colnum} values found for {streamname}\")\n",
    "    unexpected_values = found_values - master_values\n",
    "    if unexpected_values: # filter E\n",
    "        log(f\"{len(unexpected_values)} column {colnum} values in {streamname} data were unexpected:\")\n",
    "        log(','.join([str(x) for x in sorted(list(unexpected_values))]))\n",
    "    else:\n",
    "        log(f\"All values found for column {colnum} in {streamname} were expected\")\n",
    "    #log(f\"Master values: {sorted(list(master_values))}\")\n",
    "    #log(f\"Found values: {sorted(list(found_values))}\")\n",
    "    #log(f\"Missing values: {sorted(list(missing_values))}\")\n",
    "    #log(f\"Unexpected values: {sorted(list(unexpected_values))}\")\n",
    "    \n",
    "    \n",
    "    # ALSO NEED TO POPULATE participant_study BASED ON APPEARANCE IN DATA STREAM\n",
    "    \n",
    "    # JUST BEWARE THAT THIS COUNTS THE HEADER ROW AS WELL AS THE DATA ROWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T17:22:43.723069Z",
     "start_time": "2020-10-29T17:22:13.585081Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Culling telemetry data from ethica user 9409, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 5582, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5597, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5891, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5677, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 5695, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 6227, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5930, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5819, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5974, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5865, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5795, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 6091, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 5992, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 6377, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 6044, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 6402, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 6376, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 7712, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 9000, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 7441, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 8236, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 9026, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 7820, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 9005, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 8889, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 5699, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 5699, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 10581, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 10581, as instructed by linkage record\n",
      "→ Culling telemetry data from ethica user 9321, as instructed by linkage record\n",
      "→ Ignoring record for ethica user 9321, as instructed by linkage record\n",
      "→ \n",
      "There were 1541 participant records in linkage file.\n",
      "→ 567 were Ethica users.\n",
      "→ 8 were flagged as 'ignore'. (Probably test users.)\n",
      "→ 24 were flagged as 'cull'. (Probably due to known missing or corrupt data.)\n",
      "→ There are now 574 known ethica ids in the master table.\n"
     ]
    }
   ],
   "source": [
    "# Now parse the linkage file and be sure it's well formed.\n",
    "\n",
    "ignorables = set([])\n",
    "usercount = 0\n",
    "notethica = 0\n",
    "\n",
    "# read the linkage file and validate key data fields\n",
    "with open(linkage_file,'r',encoding='ISO-8859-1') as fcsv:\n",
    "    reader = csv.DictReader(fcsv,delimiter=',')\n",
    "    # optimization, should probably reduce eid values to set\n",
    "    # of unique strings first and then validate those\n",
    "    for rownum,row in enumerate(list(reader)):\n",
    "        if row['ethica_id'] or row['interact_id'] or row['study_id']:\n",
    "            usercount += 1\n",
    "        #log(f\"Reading CSV row {rownum}\")\n",
    "        eid = row['ethica_id']\n",
    "        if not eid: \n",
    "            #log(f\"CSV row #{rownum} has no eid\")\n",
    "            notethica += 1\n",
    "            continue # not an ethica row\n",
    "        if 'data_disposition' in row.keys():\n",
    "            if 'cull' in row['data_disposition']:\n",
    "                log(f\"Culling telemetry data from ethica user {eid}, as instructed by linkage record\")\n",
    "                culled_eids.add(eid)\n",
    "                # We leave the eid in the list, so that it will not show up as an unexpected id, \n",
    "                # but we also alert the operator that telemetry from this eid will be culled at ingest time\n",
    "            if 'ignore' in row['data_disposition']:\n",
    "                log(f\"Ignoring record for ethica user {eid}, as instructed by linkage record\")\n",
    "                ignorables.add(eid) # keep track of which IDs have been intentionally ignored\n",
    "                continue \n",
    "        if not validate_eid(eid, logfailures=False):\n",
    "            notethica += 1\n",
    "            continue # we're only interested in ethica users\n",
    "        iid = row['interact_id']\n",
    "        if not iid or not validate_iid(iid, logfailures=False): # filter C \n",
    "            log(f\"Ethica user {eid} has no iid\")\n",
    "        iids.add(iid)\n",
    "log(f\"\\nThere were {usercount} participant records in linkage file.\")\n",
    "#log(f\"{notethica} were not Ethica users.\")\n",
    "log(f\"{len(eids)} were Ethica users.\")\n",
    "log(f\"{len(ignorables)} were flagged as 'ignore'. (Probably test users.)\")\n",
    "log(f\"{len(culled_eids)} were flagged as 'cull'. (Probably due to known missing or corrupt data.)\")\n",
    "\n",
    "# add the ignorables to the eids so that they will not be\n",
    "# reported as unexpected\n",
    "eids = eids.union(ignorables)\n",
    "\n",
    "log(f\"There are now {len(eids)} known ethica ids in the master table.\")\n",
    "#log(eids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T03:14:49.248485Z",
     "start_time": "2020-10-29T03:12:30.378618Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ File /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/gps.csv is associated with study number 395\n",
      "→ Scanning file: /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/gps.csv\n",
      "→ File /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/gps.csv is associated with study number 396\n",
      "→ Scanning file: /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/gps.csv\n",
      "→ WARNING: User 5904 has data in conflicting studies: 396 and 395\n",
      "→ 574 user_ids found in master linkage CSV\n",
      "→ 553 distinct ethica_id values found in telemetry CSV data\n",
      "→ All expected column 1 values found for GPS\n",
      "→ All values found for column 1 in GPS were expected\n",
      "→ Participant Study Map has 553 users.\n"
     ]
    }
   ],
   "source": [
    "# And now we can verify the GPS telemetry file against the individual records we just loaded.\n",
    "# But note that for cities with multiple telemetry directories, (ie Mtl), we need to examine\n",
    "# all the data folders together, and for each file, we need to keep track of which study it\n",
    "# is associated with.\n",
    "telemetrydirs = {os.path.join(telemetrydir, 'gps.csv'):395, \n",
    "                 os.path.join(telemetrydir, 'gps.csv').replace('_en_', '_fr_'):396}\n",
    "detect_missing_values(eids, telemetrydirs, '1',  'user_id', 'GPS')\n",
    "log(f\"Participant Study Map has {len(participant_study)} users.\")\n",
    "#log(participant_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T04:31:26.593723Z",
     "start_time": "2020-10-29T03:17:19.826717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ File /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/accelerometer.csv is associated with study number 395\n",
      "→ Scanning file: /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/accelerometer.csv\n",
      "→ WARNING: User 5904 has data in conflicting studies: 395 and 396\n",
      "→ File /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/accelerometer.csv is associated with study number 396\n",
      "→ Scanning file: /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/accelerometer.csv\n",
      "→ WARNING: User 5904 has data in conflicting studies: 396 and 395\n",
      "→ 574 user_ids found in master linkage CSV\n",
      "→ 558 distinct ethica_id values found in telemetry CSV data\n",
      "→ All expected column 1 values found for Accel\n",
      "→ All values found for column 1 in Accel were expected\n",
      "→ Participant Study Map has 559 users.\n"
     ]
    }
   ],
   "source": [
    "# And again for XL telemetry\n",
    "telemetrydirs = {os.path.join(telemetrydir, 'accelerometer.csv'):395, \n",
    "                 os.path.join(telemetrydir, 'accelerometer.csv').replace('_en_', '_fr_'):396}\n",
    "detect_missing_values(eids, telemetrydirs, '1',  'user_id', 'Accel')\n",
    "log(f\"Participant Study Map has {len(participant_study)} users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hash of user_id -> study_id during the above verification DONE\n",
    "# Then add a test to find users who appear in more than one study and display a warning. DONE\n",
    "# Finally, add a mechanism to include a user in one study but exclude them from another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Linkage\n",
    "\n",
    "Once the CSV file is known to be valid and complete, we can ingest those records into the ethica_assignments table, either adding records or updating them as necessary.\n",
    "\n",
    "- FILTER OUT cull RECORDS BECAUSE THEY AREN'T REAL PARTICIPANTS\n",
    "  - MEANING: DON'T ADD THEM TO THE USER TABLE AND DON'T INGEST ANY TELEMETRY FOR THEM\n",
    "- LOAD ignore RECORDS BECAUSE THEY'RE REAL PARTICIPANTS BUT HAVE INCOMPLETE/NO TELEMETRY\n",
    "- THEN SKIP ignore USERS WHEN INGESTING TELEMETRY \n",
    "  - THEY ARE BEING IGNORED BECAUSE THEY'RE INCOMPLETE\n",
    "  - BUT INCOMPLETE DOESN'T MEAN EMPTY\n",
    "  - SO WE IGNORE THE PARTIAL DATA IF THERE IS ANY\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T16:48:00.216492Z",
     "start_time": "2020-10-28T16:47:59.714069Z"
    },
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Interact User 401563709 had no participation record for study 396. Created.\n",
      "→ Interact User 401228518 had no participation record for study 395. Created.\n",
      "→ Interact User 401837149 had no participation record for study 395. Created.\n",
      "→ Interact User 401274458 had no participation record for study 396. Created.\n",
      "→ Interact User 401866249 had no participation record for study 396. Created.\n",
      "→ Interact User 401657924 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 9409\n",
      "→ Interact User 401590820 had no participation record for study 396. Created.\n",
      "→ Interact User 401630460 had no participation record for study 395. Created.\n",
      "→ Interact User 401977519 had no participation record for study 395. Created.\n",
      "→ Interact User 401341065 had no participation record for study 396. Created.\n",
      "→ Interact User 401959928 had no participation record for study 396. Created.\n",
      "→ Interact User 401593830 had no participation record for study 396. Created.\n",
      "→ Interact User 401168982 had no participation record for study 396. Created.\n",
      "→ Interact User 401753989 had no participation record for study 396. Created.\n",
      "→ Interact User 401361426 had no participation record for study 396. Created.\n",
      "→ Interact User 401054561 had no participation record for study 396. Created.\n",
      "→ Interact User 401128162 had no participation record for study 396. Created.\n",
      "→ Interact User 401104729 had no participation record for study 395. Created.\n",
      "→ Interact User 401097960 had no participation record for study 396. Created.\n",
      "→ Interact User 401612711 had no participation record for study 396. Created.\n",
      "→ Interact User 401156162 had no participation record for study 396. Created.\n",
      "→ Interact User 401449370 had no participation record for study 396. Created.\n",
      "→ Interact User 401858062 had no participation record for study 395. Created.\n",
      "→ Interact User 401013270 had no participation record for study 396. Created.\n",
      "→ Interact User 401495302 had no participation record for study 396. Created.\n",
      "→ Interact User 401114651 had no participation record for study 396. Created.\n",
      "→ Interact User 401913808 had no participation record for study 396. Created.\n",
      "→ Interact User 401184984 had no participation record for study 396. Created.\n",
      "→ INTERACT USER 401184984 ALREADY EXISTS IN STUDY 396!\n",
      "→ Interact User 401291427 had no participation record for study 396. Created.\n",
      "→ Interact User 401143240 had no participation record for study 396. Created.\n",
      "→ Interact User 401895922 had no participation record for study 396. Created.\n",
      "→ Interact User 401595508 had no participation record for study 396. Created.\n",
      "→ Interact User 401430588 had no participation record for study 396. Created.\n",
      "→ Interact User 401561705 had no participation record for study 395. Created.\n",
      "→ Interact User 401959741 had no participation record for study 396. Created.\n",
      "→ Interact User 401170360 had no participation record for study 396. Created.\n",
      "→ Interact User 401729416 had no participation record for study 396. Created.\n",
      "→ Interact User 401213122 had no participation record for study 396. Created.\n",
      "→ Interact User 401460946 had no participation record for study 396. Created.\n",
      "→ Skipping creation of record for ethica_id 5582 based on 'ignore' flag.\n",
      "→ Interact User 401442080 had no participation record for study 396. Created.\n",
      "→ Interact User 401807288 had no participation record for study 396. Created.\n",
      "→ Interact User 401432702 had no participation record for study 396. Created.\n",
      "→ Interact User 401145591 had no participation record for study 395. Created.\n",
      "→ Interact User 401849437 had no participation record for study 396. Created.\n",
      "→ Interact User 401796474 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 5597\n",
      "→ Interact User 401196235 had no participation record for study 395. Created.\n",
      "→ Interact User 401915414 had no participation record for study 396. Created.\n",
      "→ Interact User 401713668 had no participation record for study 396. Created.\n",
      "→ Interact User 401427283 had no participation record for study 396. Created.\n",
      "→ Interact User 401464124 had no participation record for study 396. Created.\n",
      "→ Interact User 401079598 had no participation record for study 396. Created.\n",
      "→ Interact User 401530900 had no participation record for study 396. Created.\n",
      "→ Interact User 401313041 had no participation record for study 396. Created.\n",
      "→ Interact User 401080308 had no participation record for study 396. Created.\n",
      "→ Interact User 401387517 had no participation record for study 396. Created.\n",
      "→ Interact User 401060949 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 5891\n",
      "→ Skipping creation of participation record for ethica test user 5677\n",
      "→ Interact User 401416333 had no participation record for study 396. Created.\n",
      "→ Interact User 401693757 had no participation record for study 396. Created.\n",
      "→ Interact User 401510568 had no participation record for study 395. Created.\n",
      "→ Interact User 401535747 had no participation record for study 395. Created.\n",
      "→ Interact User 401568172 had no participation record for study 396. Created.\n",
      "→ Interact User 401064220 had no participation record for study 396. Created.\n",
      "→ Interact User 401544321 had no participation record for study 395. Created.\n",
      "→ Interact User 401651614 had no participation record for study 396. Created.\n",
      "→ Interact User 401406511 had no participation record for study 396. Created.\n",
      "→ Interact User 401755253 had no participation record for study 396. Created.\n",
      "→ Interact User 401957705 had no participation record for study 396. Created.\n",
      "→ Interact User 401513068 had no participation record for study 396. Created.\n",
      "→ Interact User 401461413 had no participation record for study 396. Created.\n",
      "→ Interact User 401015259 had no participation record for study 395. Created.\n",
      "→ Interact User 401882892 had no participation record for study 396. Created.\n",
      "→ Interact User 401199969 had no participation record for study 396. Created.\n",
      "→ Interact User 401389076 had no participation record for study 396. Created.\n",
      "→ Interact User 401114382 had no participation record for study 396. Created.\n",
      "→ Interact User 401240793 had no participation record for study 396. Created.\n",
      "→ Interact User 401273372 had no participation record for study 396. Created.\n",
      "→ Interact User 401805387 had no participation record for study 395. Created.\n",
      "→ Interact User 401249729 had no participation record for study 396. Created.\n",
      "→ Interact User 401095730 had no participation record for study 395. Created.\n",
      "→ Interact User 401871592 had no participation record for study 396. Created.\n",
      "→ Interact User 401937882 had no participation record for study 396. Created.\n",
      "→ Interact User 401986577 had no participation record for study 395. Created.\n",
      "→ Interact User 401264767 had no participation record for study 395. Created.\n",
      "→ Interact User 401117024 had no participation record for study 396. Created.\n",
      "→ Interact User 401742600 had no participation record for study 395. Created.\n",
      "→ Interact User 401406485 had no participation record for study 396. Created.\n",
      "→ Interact User 401714256 had no participation record for study 395. Created.\n",
      "→ Interact User 401828689 had no participation record for study 396. Created.\n",
      "→ Interact User 401669659 had no participation record for study 396. Created.\n",
      "→ Interact User 401635772 had no participation record for study 396. Created.\n",
      "→ Interact User 401104314 had no participation record for study 396. Created.\n",
      "→ Interact User 401851363 had no participation record for study 396. Created.\n",
      "→ Interact User 401396160 had no participation record for study 396. Created.\n",
      "→ Interact User 401374682 had no participation record for study 396. Created.\n",
      "→ Interact User 401702019 had no participation record for study 396. Created.\n",
      "→ Interact User 401785805 had no participation record for study 396. Created.\n",
      "→ Interact User 401010101 had no participation record for study 396. Created.\n",
      "→ Interact User 401793448 had no participation record for study 396. Created.\n",
      "→ Interact User 401299623 had no participation record for study 395. Created.\n",
      "→ Interact User 401887854 had no participation record for study 396. Created.\n",
      "→ Interact User 401547018 had no participation record for study 396. Created.\n",
      "→ Interact User 401902483 had no participation record for study 395. Created.\n",
      "→ Interact User 401406732 had no participation record for study 396. Created.\n",
      "→ Interact User 401291822 had no participation record for study 395. Created.\n",
      "→ Interact User 401601884 had no participation record for study 395. Created.\n",
      "→ Interact User 401001817 had no participation record for study 396. Created.\n",
      "→ Interact User 401834531 had no participation record for study 396. Created.\n",
      "→ Interact User 401474912 had no participation record for study 395. Created.\n",
      "→ Interact User 401176972 had no participation record for study 396. Created.\n",
      "→ Interact User 401430341 had no participation record for study 396. Created.\n",
      "→ Interact User 401586738 had no participation record for study 396. Created.\n",
      "→ Interact User 401519033 had no participation record for study 396. Created.\n",
      "→ Interact User 401921798 had no participation record for study 396. Created.\n",
      "→ Interact User 401186649 had no participation record for study 396. Created.\n",
      "→ Interact User 401522734 had no participation record for study 396. Created.\n",
      "→ Interact User 401143038 had no participation record for study 396. Created.\n",
      "→ Interact User 401471437 had no participation record for study 396. Created.\n",
      "→ Interact User 401399862 had no participation record for study 396. Created.\n",
      "→ Interact User 401809607 had no participation record for study 396. Created.\n",
      "→ Interact User 401943618 had no participation record for study 396. Created.\n",
      "→ Interact User 401798988 had no participation record for study 396. Created.\n",
      "→ Interact User 401844948 had no participation record for study 396. Created.\n",
      "→ Interact User 401687877 had no participation record for study 396. Created.\n",
      "→ Interact User 401682837 had no participation record for study 396. Created.\n",
      "→ Interact User 401041455 had no participation record for study 396. Created.\n",
      "→ Interact User 401206271 had no participation record for study 396. Created.\n",
      "→ Interact User 401639662 had no participation record for study 396. Created.\n",
      "→ Interact User 401479258 had no participation record for study 396. Created.\n",
      "→ Interact User 401867550 had no participation record for study 396. Created.\n",
      "→ Interact User 401129083 had no participation record for study 396. Created.\n",
      "→ Interact User 401758114 had no participation record for study 396. Created.\n",
      "→ Interact User 401159830 had no participation record for study 396. Created.\n",
      "→ Interact User 401316926 had no participation record for study 396. Created.\n",
      "→ Skipping creation of record for ethica_id 5695 based on 'ignore' flag.\n",
      "→ Interact User 401310812 had no participation record for study 396. Created.\n",
      "→ Interact User 401043675 had no participation record for study 396. Created.\n",
      "→ Interact User 401674061 had no participation record for study 396. Created.\n",
      "→ Interact User 401567962 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 6227\n",
      "→ Interact User 401454440 had no participation record for study 396. Created.\n",
      "→ Interact User 401341238 had no participation record for study 396. Created.\n",
      "→ Interact User 401018766 had no participation record for study 395. Created.\n",
      "→ Interact User 401380878 had no participation record for study 396. Created.\n",
      "→ Interact User 401855938 had no participation record for study 396. Created.\n",
      "→ Interact User 401017349 had no participation record for study 396. Created.\n",
      "→ Interact User 401715797 had no participation record for study 396. Created.\n",
      "→ Interact User 401769034 had no participation record for study 396. Created.\n",
      "→ Interact User 401910133 had no participation record for study 396. Created.\n",
      "→ Interact User 401084747 had no participation record for study 396. Created.\n",
      "→ Interact User 401249230 had no participation record for study 396. Created.\n",
      "→ Interact User 401632348 had no participation record for study 396. Created.\n",
      "→ Interact User 401493283 had no participation record for study 396. Created.\n",
      "→ Interact User 401303680 had no participation record for study 396. Created.\n",
      "→ Interact User 401607983 had no participation record for study 396. Created.\n",
      "→ Interact User 401087007 had no participation record for study 396. Created.\n",
      "→ Interact User 401750212 had no participation record for study 396. Created.\n",
      "→ Interact User 401885616 had no participation record for study 396. Created.\n",
      "→ Interact User 401723945 had no participation record for study 396. Created.\n",
      "→ Interact User 401483463 had no participation record for study 396. Created.\n",
      "→ Interact User 401082893 had no participation record for study 396. Created.\n",
      "→ Interact User 401948941 had no participation record for study 396. Created.\n",
      "→ Interact User 401406377 had no participation record for study 396. Created.\n",
      "→ Interact User 401936329 had no participation record for study 396. Created.\n",
      "→ Interact User 401109691 had no participation record for study 396. Created.\n",
      "→ Interact User 401544738 had no participation record for study 396. Created.\n",
      "→ Interact User 401368714 had no participation record for study 396. Created.\n",
      "→ Interact User 401104909 had no participation record for study 396. Created.\n",
      "→ Interact User 401942285 had no participation record for study 396. Created.\n",
      "→ Interact User 401822088 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 5930\n",
      "→ Interact User 401068153 had no participation record for study 396. Created.\n",
      "→ Interact User 401507474 had no participation record for study 396. Created.\n",
      "→ Interact User 401214720 had no participation record for study 396. Created.\n",
      "→ Interact User 401312953 had no participation record for study 396. Created.\n",
      "→ Interact User 401719979 had no participation record for study 396. Created.\n",
      "→ Interact User 401071894 had no participation record for study 396. Created.\n",
      "→ Interact User 401473531 had no participation record for study 396. Created.\n",
      "→ Interact User 401740972 had no participation record for study 396. Created.\n",
      "→ Interact User 401142217 had no participation record for study 396. Created.\n",
      "→ Interact User 401717838 had no participation record for study 396. Created.\n",
      "→ Interact User 401599541 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 5819\n",
      "→ Interact User 401815437 had no participation record for study 396. Created.\n",
      "→ Interact User 401259422 had no participation record for study 396. Created.\n",
      "→ Interact User 401545947 had no participation record for study 396. Created.\n",
      "→ Interact User 401469801 had no participation record for study 396. Created.\n",
      "→ Interact User 401567520 had no participation record for study 396. Created.\n",
      "→ Interact User 401331963 had no participation record for study 396. Created.\n",
      "→ Interact User 401077819 had no participation record for study 395. Created.\n",
      "→ Interact User 401201805 had no participation record for study 396. Created.\n",
      "→ Interact User 401778226 had no participation record for study 396. Created.\n",
      "→ Interact User 401277679 had no participation record for study 396. Created.\n",
      "→ Interact User 401553707 had no participation record for study 396. Created.\n",
      "→ Interact User 401285374 had no participation record for study 396. Created.\n",
      "→ Interact User 401989908 had no participation record for study 396. Created.\n",
      "→ Interact User 401664309 had no participation record for study 396. Created.\n",
      "→ Interact User 401282187 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 5974\n",
      "→ Skipping creation of participation record for ethica test user 5865\n",
      "→ Interact User 401014707 had no participation record for study 396. Created.\n",
      "→ Interact User 401936842 had no participation record for study 396. Created.\n",
      "→ Interact User 401811306 had no participation record for study 396. Created.\n",
      "→ Interact User 401605376 had no participation record for study 396. Created.\n",
      "→ Interact User 401984105 had no participation record for study 396. Created.\n",
      "→ Interact User 401556590 had no participation record for study 396. Created.\n",
      "→ Interact User 401208681 had no participation record for study 396. Created.\n",
      "→ Interact User 401522395 had no participation record for study 396. Created.\n",
      "→ Interact User 401826476 had no participation record for study 396. Created.\n",
      "→ Interact User 401720955 had no participation record for study 396. Created.\n",
      "→ Interact User 401067509 had no participation record for study 396. Created.\n",
      "→ Interact User 401327712 had no participation record for study 396. Created.\n",
      "→ Interact User 401405053 had no participation record for study 396. Created.\n",
      "→ Interact User 401278478 had no participation record for study 395. Created.\n",
      "→ Interact User 401658127 had no participation record for study 395. Created.\n",
      "→ Interact User 401257547 had no participation record for study 395. Created.\n",
      "→ Interact User 401454953 had no participation record for study 395. Created.\n",
      "→ Interact User 401231192 had no participation record for study 396. Created.\n",
      "→ Interact User 401775470 had no participation record for study 396. Created.\n",
      "→ Interact User 401911823 had no participation record for study 396. Created.\n",
      "→ Interact User 401499071 had no participation record for study 396. Created.\n",
      "→ Interact User 401263827 had no participation record for study 396. Created.\n",
      "→ Interact User 401379028 had no participation record for study 396. Created.\n",
      "→ Interact User 401471476 had no participation record for study 396. Created.\n",
      "→ Interact User 401802409 had no participation record for study 396. Created.\n",
      "→ Interact User 401869857 had no participation record for study 396. Created.\n",
      "→ Interact User 401279983 had no participation record for study 396. Created.\n",
      "→ Interact User 401211351 had no participation record for study 396. Created.\n",
      "→ Interact User 401010635 had no participation record for study 395. Created.\n",
      "→ Interact User 401449636 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 5795\n",
      "→ Interact User 401776465 had no participation record for study 396. Created.\n",
      "→ Interact User 401976026 had no participation record for study 396. Created.\n",
      "→ Interact User 401178700 had no participation record for study 396. Created.\n",
      "→ Interact User 401240419 had no participation record for study 396. Created.\n",
      "→ Interact User 401890990 had no participation record for study 396. Created.\n",
      "→ Interact User 401659853 had no participation record for study 396. Created.\n",
      "→ Interact User 401341482 had no participation record for study 396. Created.\n",
      "→ Interact User 401055965 had no participation record for study 395. Created.\n",
      "→ Interact User 401638846 had no participation record for study 396. Created.\n",
      "→ Interact User 401313591 had no participation record for study 395. Created.\n",
      "→ Interact User 401189367 had no participation record for study 396. Created.\n",
      "→ Interact User 401977265 had no participation record for study 396. Created.\n",
      "→ Interact User 401140393 had no participation record for study 396. Created.\n",
      "→ Interact User 401172157 had no participation record for study 396. Created.\n",
      "→ Interact User 401854011 had no participation record for study 396. Created.\n",
      "→ Interact User 401121461 had no participation record for study 396. Created.\n",
      "→ Interact User 401416692 had no participation record for study 396. Created.\n",
      "→ Interact User 401926082 had no participation record for study 396. Created.\n",
      "→ Interact User 401188567 had no participation record for study 396. Created.\n",
      "→ Interact User 401465378 had no participation record for study 396. Created.\n",
      "→ Interact User 401774805 had no participation record for study 396. Created.\n",
      "→ Interact User 401581644 had no participation record for study 396. Created.\n",
      "→ Interact User 401968762 had no participation record for study 396. Created.\n",
      "→ Interact User 401899217 had no participation record for study 395. Created.\n",
      "→ Interact User 401855160 had no participation record for study 396. Created.\n",
      "→ Interact User 401380365 had no participation record for study 396. Created.\n",
      "→ Interact User 401505571 had no participation record for study 396. Created.\n",
      "→ Interact User 401952301 had no participation record for study 396. Created.\n",
      "→ Interact User 401925805 had no participation record for study 396. Created.\n",
      "→ Interact User 401384579 had no participation record for study 396. Created.\n",
      "→ Interact User 401299702 had no participation record for study 396. Created.\n",
      "→ Interact User 401742896 had no participation record for study 395. Created.\n",
      "→ Interact User 401305353 had no participation record for study 395. Created.\n",
      "→ Interact User 401941869 had no participation record for study 396. Created.\n",
      "→ Interact User 401493980 had no participation record for study 396. Created.\n",
      "→ Interact User 401747663 had no participation record for study 396. Created.\n",
      "→ Interact User 401157310 had no participation record for study 396. Created.\n",
      "→ Interact User 401995939 had no participation record for study 396. Created.\n",
      "→ Interact User 401896632 had no participation record for study 396. Created.\n",
      "→ Interact User 401879695 had no participation record for study 396. Created.\n",
      "→ Interact User 401655897 had no participation record for study 396. Created.\n",
      "→ Interact User 401690625 had no participation record for study 396. Created.\n",
      "→ Interact User 401490862 had no participation record for study 396. Created.\n",
      "→ Interact User 401219095 had no participation record for study 396. Created.\n",
      "→ Interact User 401309906 had no participation record for study 396. Created.\n",
      "→ Interact User 401630535 had no participation record for study 396. Created.\n",
      "→ Interact User 401197509 had no participation record for study 396. Created.\n",
      "→ Interact User 401877806 had no participation record for study 396. Created.\n",
      "→ Interact User 401868074 had no participation record for study 396. Created.\n",
      "→ Interact User 401118275 had no participation record for study 396. Created.\n",
      "→ Interact User 401480375 had no participation record for study 396. Created.\n",
      "→ Interact User 401098180 had no participation record for study 395. Created.\n",
      "→ Skipping creation of participation record for ethica test user 6091\n",
      "→ Interact User 401927418 had no participation record for study 396. Created.\n",
      "→ Interact User 401242693 had no participation record for study 396. Created.\n",
      "→ Interact User 401576979 had no participation record for study 396. Created.\n",
      "→ Interact User 401223918 had no participation record for study 396. Created.\n",
      "→ Interact User 401448284 had no participation record for study 396. Created.\n",
      "→ Interact User 401947775 had no participation record for study 396. Created.\n",
      "→ Interact User 401318330 had no participation record for study 396. Created.\n",
      "→ Interact User 401326762 had no participation record for study 396. Created.\n",
      "→ Interact User 401524297 had no participation record for study 396. Created.\n",
      "→ Interact User 401362151 had no participation record for study 396. Created.\n",
      "→ Interact User 401194946 had no participation record for study 396. Created.\n",
      "→ Interact User 401340147 had no participation record for study 396. Created.\n",
      "→ Interact User 401590220 had no participation record for study 396. Created.\n",
      "→ Interact User 401410372 had no participation record for study 396. Created.\n",
      "→ Interact User 401423466 had no participation record for study 396. Created.\n",
      "→ Interact User 401203454 had no participation record for study 395. Created.\n",
      "→ Interact User 401524229 had no participation record for study 396. Created.\n",
      "→ Interact User 401652752 had no participation record for study 396. Created.\n",
      "→ Interact User 401756345 had no participation record for study 396. Created.\n",
      "→ Interact User 401875982 had no participation record for study 396. Created.\n",
      "→ Interact User 401952428 had no participation record for study 396. Created.\n",
      "→ Interact User 401831490 had no participation record for study 396. Created.\n",
      "→ Interact User 401706561 had no participation record for study 396. Created.\n",
      "→ Interact User 401475306 had no participation record for study 396. Created.\n",
      "→ Interact User 401502363 had no participation record for study 396. Created.\n",
      "→ Interact User 401910151 had no participation record for study 396. Created.\n",
      "→ Interact User 401030297 had no participation record for study 396. Created.\n",
      "→ Interact User 401016540 had no participation record for study 396. Created.\n",
      "→ INTERACT USER 401016540 ALREADY EXISTS IN STUDY 396!\n",
      "→ Skipping creation of record for ethica_id 5992 based on 'ignore' flag.\n",
      "→ Interact User 401277385 had no participation record for study 396. Created.\n",
      "→ Interact User 401650118 had no participation record for study 396. Created.\n",
      "→ Interact User 401920728 had no participation record for study 396. Created.\n",
      "→ Interact User 401357026 had no participation record for study 396. Created.\n",
      "→ Interact User 401316775 had no participation record for study 396. Created.\n",
      "→ Interact User 401610003 had no participation record for study 396. Created.\n",
      "→ Interact User 401804480 had no participation record for study 396. Created.\n",
      "→ Interact User 401248970 had no participation record for study 396. Created.\n",
      "→ Interact User 401600639 had no participation record for study 396. Created.\n",
      "→ Interact User 401342134 had no participation record for study 396. Created.\n",
      "→ Interact User 401419362 had no participation record for study 396. Created.\n",
      "→ Interact User 401534107 had no participation record for study 396. Created.\n",
      "→ Interact User 401272903 had no participation record for study 396. Created.\n",
      "→ Interact User 401592150 had no participation record for study 396. Created.\n",
      "→ Interact User 401400173 had no participation record for study 396. Created.\n",
      "→ Interact User 401167164 had no participation record for study 396. Created.\n",
      "→ Interact User 401334883 had no participation record for study 396. Created.\n",
      "→ Interact User 401812917 had no participation record for study 396. Created.\n",
      "→ Interact User 401400255 had no participation record for study 396. Created.\n",
      "→ Interact User 401315327 had no participation record for study 396. Created.\n",
      "→ Interact User 401392810 had no participation record for study 396. Created.\n",
      "→ Interact User 401005392 had no participation record for study 396. Created.\n",
      "→ Interact User 401939455 had no participation record for study 396. Created.\n",
      "→ Interact User 401538242 had no participation record for study 396. Created.\n",
      "→ Interact User 401402485 had no participation record for study 396. Created.\n",
      "→ Interact User 401831853 had no participation record for study 396. Created.\n",
      "→ Interact User 401814489 had no participation record for study 396. Created.\n",
      "→ Interact User 401123877 had no participation record for study 395. Created.\n",
      "→ Interact User 401249937 had no participation record for study 396. Created.\n",
      "→ Interact User 401040500 had no participation record for study 396. Created.\n",
      "→ Interact User 401691038 had no participation record for study 396. Created.\n",
      "→ Interact User 401058797 had no participation record for study 396. Created.\n",
      "→ Interact User 401034467 had no participation record for study 396. Created.\n",
      "→ Interact User 401154165 had no participation record for study 396. Created.\n",
      "→ Interact User 401775018 had no participation record for study 396. Created.\n",
      "→ Interact User 401040292 had no participation record for study 396. Created.\n",
      "→ Interact User 401223433 had no participation record for study 396. Created.\n",
      "→ Interact User 401520936 had no participation record for study 396. Created.\n",
      "→ Interact User 401104058 had no participation record for study 396. Created.\n",
      "→ Interact User 401860045 had no participation record for study 396. Created.\n",
      "→ Interact User 401548222 had no participation record for study 396. Created.\n",
      "→ Interact User 401753339 had no participation record for study 396. Created.\n",
      "→ Interact User 401210141 had no participation record for study 396. Created.\n",
      "→ Interact User 401128981 had no participation record for study 396. Created.\n",
      "→ Interact User 401236761 had no participation record for study 396. Created.\n",
      "→ Interact User 401839530 had no participation record for study 396. Created.\n",
      "→ Interact User 401554981 had no participation record for study 396. Created.\n",
      "→ Interact User 401325830 had no participation record for study 396. Created.\n",
      "→ Interact User 401885249 had no participation record for study 396. Created.\n",
      "→ Interact User 401180544 had no participation record for study 396. Created.\n",
      "→ Interact User 401256133 had no participation record for study 396. Created.\n",
      "→ Interact User 401212334 had no participation record for study 396. Created.\n",
      "→ Interact User 401726192 had no participation record for study 396. Created.\n",
      "→ Interact User 401300631 had no participation record for study 396. Created.\n",
      "→ Interact User 401590344 had no participation record for study 395. Created.\n",
      "→ Interact User 401488959 had no participation record for study 396. Created.\n",
      "→ Interact User 401370219 had no participation record for study 395. Created.\n",
      "→ Interact User 401377103 had no participation record for study 395. Created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Interact User 401151515 had no participation record for study 395. Created.\n",
      "→ Interact User 401533666 had no participation record for study 395. Created.\n",
      "→ Interact User 401159940 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 6377\n",
      "→ Interact User 401573388 had no participation record for study 395. Created.\n",
      "→ Interact User 401189457 had no participation record for study 396. Created.\n",
      "→ Interact User 401484804 had no participation record for study 396. Created.\n",
      "→ Interact User 401796223 had no participation record for study 395. Created.\n",
      "→ Interact User 401309336 had no participation record for study 395. Created.\n",
      "→ Interact User 401601193 had no participation record for study 396. Created.\n",
      "→ Interact User 401367601 had no participation record for study 396. Created.\n",
      "→ Interact User 401888182 had no participation record for study 396. Created.\n",
      "→ Interact User 401149339 had no participation record for study 395. Created.\n",
      "→ Interact User 401856164 had no participation record for study 395. Created.\n",
      "→ Interact User 401750427 had no participation record for study 395. Created.\n",
      "→ Interact User 401371665 had no participation record for study 395. Created.\n",
      "→ Interact User 401303173 had no participation record for study 395. Created.\n",
      "→ Interact User 401754630 had no participation record for study 396. Created.\n",
      "→ Interact User 401923080 had no participation record for study 395. Created.\n",
      "→ Interact User 401057692 had no participation record for study 395. Created.\n",
      "→ Interact User 401478512 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 6044\n",
      "→ Interact User 401584651 had no participation record for study 395. Created.\n",
      "→ Interact User 401556493 had no participation record for study 395. Created.\n",
      "→ Interact User 401020737 had no participation record for study 395. Created.\n",
      "→ Interact User 401707723 had no participation record for study 395. Created.\n",
      "→ Interact User 401016019 had no participation record for study 396. Created.\n",
      "→ Interact User 401465720 had no participation record for study 396. Created.\n",
      "→ Interact User 401997401 had no participation record for study 396. Created.\n",
      "→ Interact User 401688111 had no participation record for study 396. Created.\n",
      "→ Interact User 401514073 had no participation record for study 396. Created.\n",
      "→ Interact User 401709298 had no participation record for study 396. Created.\n",
      "→ Interact User 401204379 had no participation record for study 396. Created.\n",
      "→ Interact User 401072740 had no participation record for study 396. Created.\n",
      "→ Interact User 401914555 had no participation record for study 395. Created.\n",
      "→ Interact User 401093777 had no participation record for study 396. Created.\n",
      "→ Interact User 401538310 had no participation record for study 395. Created.\n",
      "→ Interact User 401278792 had no participation record for study 396. Created.\n",
      "→ Interact User 401491335 had no participation record for study 395. Created.\n",
      "→ Interact User 401615346 had no participation record for study 395. Created.\n",
      "→ Interact User 401034573 had no participation record for study 396. Created.\n",
      "→ Interact User 401718681 had no participation record for study 396. Created.\n",
      "→ Interact User 401047099 had no participation record for study 395. Created.\n",
      "→ Interact User 401292777 had no participation record for study 396. Created.\n",
      "→ Interact User 401594705 had no participation record for study 396. Created.\n",
      "→ Interact User 401460096 had no participation record for study 395. Created.\n",
      "→ Interact User 401396832 had no participation record for study 395. Created.\n",
      "→ Interact User 401677382 had no participation record for study 396. Created.\n",
      "→ Interact User 401239342 had no participation record for study 396. Created.\n",
      "→ Interact User 401918877 had no participation record for study 395. Created.\n",
      "→ Interact User 401593105 had no participation record for study 396. Created.\n",
      "→ Interact User 401083325 had no participation record for study 396. Created.\n",
      "→ Interact User 401764241 had no participation record for study 396. Created.\n",
      "→ Interact User 401751809 had no participation record for study 396. Created.\n",
      "→ Interact User 401161176 had no participation record for study 395. Created.\n",
      "→ Interact User 401029256 had no participation record for study 395. Created.\n",
      "→ Interact User 401681407 had no participation record for study 396. Created.\n",
      "→ Interact User 401017069 had no participation record for study 396. Created.\n",
      "→ Interact User 401660649 had no participation record for study 396. Created.\n",
      "→ Interact User 401339944 had no participation record for study 396. Created.\n",
      "→ Interact User 401795036 had no participation record for study 396. Created.\n",
      "→ Interact User 401315400 had no participation record for study 396. Created.\n",
      "→ Interact User 401500689 had no participation record for study 396. Created.\n",
      "→ Interact User 401171523 had no participation record for study 396. Created.\n",
      "→ Interact User 401796248 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 6402\n",
      "→ Skipping creation of participation record for ethica test user 6376\n",
      "→ Interact User 401720270 had no participation record for study 396. Created.\n",
      "→ Interact User 401153207 had no participation record for study 396. Created.\n",
      "→ Interact User 401532425 had no participation record for study 396. Created.\n",
      "→ Interact User 401805034 had no participation record for study 396. Created.\n",
      "→ Interact User 401998921 had no participation record for study 395. Created.\n",
      "→ Interact User 401146874 had no participation record for study 396. Created.\n",
      "→ Interact User 401841730 had no participation record for study 396. Created.\n",
      "→ Interact User 401928299 had no participation record for study 395. Created.\n",
      "→ Interact User 401690007 had no participation record for study 396. Created.\n",
      "→ Interact User 401303857 had no participation record for study 396. Created.\n",
      "→ Interact User 401633041 had no participation record for study 396. Created.\n",
      "→ Interact User 401522186 had no participation record for study 396. Created.\n",
      "→ Interact User 401570621 had no participation record for study 396. Created.\n",
      "→ Interact User 401842092 had no participation record for study 396. Created.\n",
      "→ Interact User 401462227 had no participation record for study 396. Created.\n",
      "→ Interact User 401678459 had no participation record for study 396. Created.\n",
      "→ Interact User 401210457 had no participation record for study 396. Created.\n",
      "→ Interact User 401293896 had no participation record for study 396. Created.\n",
      "→ Interact User 401379272 had no participation record for study 396. Created.\n",
      "→ Interact User 401852730 had no participation record for study 395. Created.\n",
      "→ Interact User 401421168 had no participation record for study 396. Created.\n",
      "→ Interact User 401177371 had no participation record for study 396. Created.\n",
      "→ Interact User 401021150 had no participation record for study 396. Created.\n",
      "→ Interact User 401689880 had no participation record for study 395. Created.\n",
      "→ Interact User 401211139 had no participation record for study 396. Created.\n",
      "→ Interact User 401337828 had no participation record for study 395. Created.\n",
      "→ Interact User 401655906 had no participation record for study 395. Created.\n",
      "→ Interact User 401594975 had no participation record for study 396. Created.\n",
      "→ Interact User 401604911 had no participation record for study 395. Created.\n",
      "→ Interact User 401967217 had no participation record for study 396. Created.\n",
      "→ Interact User 401905412 had no participation record for study 396. Created.\n",
      "→ Interact User 401818388 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 7712\n",
      "→ Interact User 401801548 had no participation record for study 396. Created.\n",
      "→ Interact User 401879844 had no participation record for study 395. Created.\n",
      "→ Interact User 401839715 had no participation record for study 396. Created.\n",
      "→ Interact User 401461435 had no participation record for study 396. Created.\n",
      "→ Interact User 401530157 had no participation record for study 396. Created.\n",
      "→ Interact User 401216016 had no participation record for study 395. Created.\n",
      "→ Interact User 401419293 had no participation record for study 396. Created.\n",
      "→ Interact User 401078129 had no participation record for study 395. Created.\n",
      "→ Interact User 401272407 had no participation record for study 396. Created.\n",
      "→ Interact User 401930699 had no participation record for study 396. Created.\n",
      "→ Interact User 401365505 had no participation record for study 396. Created.\n",
      "→ Interact User 401118544 had no participation record for study 396. Created.\n",
      "→ Interact User 401336772 had no participation record for study 395. Created.\n",
      "→ Skipping creation of record for ethica_id 9000 based on 'ignore' flag.\n",
      "→ Interact User 401794213 had no participation record for study 396. Created.\n",
      "→ Interact User 401273284 had no participation record for study 396. Created.\n",
      "→ Interact User 401686470 had no participation record for study 396. Created.\n",
      "→ Interact User 401995978 had no participation record for study 396. Created.\n",
      "→ Interact User 401819456 had no participation record for study 395. Created.\n",
      "→ Interact User 401915749 had no participation record for study 396. Created.\n",
      "→ Interact User 401386983 had no participation record for study 396. Created.\n",
      "→ Interact User 401907783 had no participation record for study 396. Created.\n",
      "→ Interact User 401399757 had no participation record for study 396. Created.\n",
      "→ Interact User 401130608 had no participation record for study 396. Created.\n",
      "→ Interact User 401535733 had no participation record for study 396. Created.\n",
      "→ Interact User 401756882 had no participation record for study 396. Created.\n",
      "→ Interact User 401703298 had no participation record for study 396. Created.\n",
      "→ Interact User 401201353 had no participation record for study 396. Created.\n",
      "→ Interact User 401102101 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 7441\n",
      "→ Interact User 401465715 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 8236\n",
      "→ Interact User 401249296 had no participation record for study 396. Created.\n",
      "→ Interact User 401152941 had no participation record for study 396. Created.\n",
      "→ Interact User 401876240 had no participation record for study 396. Created.\n",
      "→ Interact User 401760345 had no participation record for study 396. Created.\n",
      "→ Interact User 401450953 had no participation record for study 396. Created.\n",
      "→ Interact User 401379232 had no participation record for study 396. Created.\n",
      "→ Interact User 401430409 had no participation record for study 395. Created.\n",
      "→ Interact User 401933176 had no participation record for study 396. Created.\n",
      "→ Interact User 401571603 had no participation record for study 396. Created.\n",
      "→ Interact User 401464914 had no participation record for study 396. Created.\n",
      "→ Interact User 401272178 had no participation record for study 396. Created.\n",
      "→ Interact User 401409118 had no participation record for study 395. Created.\n",
      "→ Interact User 401133068 had no participation record for study 396. Created.\n",
      "→ Interact User 401456229 had no participation record for study 396. Created.\n",
      "→ Interact User 401607198 had no participation record for study 396. Created.\n",
      "→ Interact User 401841351 had no participation record for study 395. Created.\n",
      "→ Interact User 401935700 had no participation record for study 396. Created.\n",
      "→ Interact User 401841090 had no participation record for study 396. Created.\n",
      "→ Interact User 401035210 had no participation record for study 396. Created.\n",
      "→ Interact User 401950248 had no participation record for study 396. Created.\n",
      "→ Interact User 401214740 had no participation record for study 396. Created.\n",
      "→ Interact User 401428166 had no participation record for study 395. Created.\n",
      "→ Interact User 401369752 had no participation record for study 396. Created.\n",
      "→ Interact User 401411472 had no participation record for study 396. Created.\n",
      "→ Interact User 401361650 had no participation record for study 396. Created.\n",
      "→ Interact User 401085103 had no participation record for study 396. Created.\n",
      "→ Interact User 401340374 had no participation record for study 396. Created.\n",
      "→ Interact User 401446699 had no participation record for study 396. Created.\n",
      "→ Interact User 401721002 had no participation record for study 396. Created.\n",
      "→ Skipping creation of record for ethica_id 9026 based on 'ignore' flag.\n",
      "→ Interact User 401102511 had no participation record for study 395. Created.\n",
      "→ Interact User 401782901 had no participation record for study 396. Created.\n",
      "→ Interact User 401752364 had no participation record for study 396. Created.\n",
      "→ Interact User 401677857 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 7820\n",
      "→ Interact User 401484028 had no participation record for study 396. Created.\n",
      "→ Interact User 401851002 had no participation record for study 395. Created.\n",
      "→ Interact User 401333723 had no participation record for study 395. Created.\n",
      "→ Interact User 401589224 had no participation record for study 396. Created.\n",
      "→ Interact User 401917512 had no participation record for study 395. Created.\n",
      "→ Interact User 401514022 had no participation record for study 396. Created.\n",
      "→ Interact User 401969922 had no participation record for study 396. Created.\n",
      "→ Interact User 401510896 had no participation record for study 396. Created.\n",
      "→ Interact User 401482649 had no participation record for study 396. Created.\n",
      "→ Interact User 401172774 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 9005\n",
      "→ Interact User 401417351 had no participation record for study 396. Created.\n",
      "→ Interact User 401314011 had no participation record for study 396. Created.\n",
      "→ Interact User 401658250 had no participation record for study 396. Created.\n",
      "→ Interact User 401919451 had no participation record for study 396. Created.\n",
      "→ Interact User 401825200 had no participation record for study 396. Created.\n",
      "→ Skipping creation of participation record for ethica test user 8889\n",
      "→ Interact User 401212573 had no participation record for study 396. Created.\n",
      "→ Interact User 401968222 had no participation record for study 396. Created.\n",
      "→ Interact User 401354259 had no participation record for study 396. Created.\n",
      "→ Interact User 401178032 had no participation record for study 395. Created.\n",
      "→ Interact User 401092815 had no participation record for study 395. Created.\n",
      "→ Interact User 401746090 had no participation record for study 395. Created.\n",
      "→ Interact User 401937896 had no participation record for study 396. Created.\n",
      "→ Interact User 401440362 had no participation record for study 396. Created.\n",
      "→ Interact User 401103480 had no participation record for study 396. Created.\n",
      "→ Interact User 401330614 had no participation record for study 396. Created.\n",
      "→ Interact User 401876110 had no participation record for study 396. Created.\n",
      "→ Interact User 401132844 had no participation record for study 396. Created.\n",
      "→ Interact User 401484684 had no participation record for study 396. Created.\n",
      "→ Skipping creation of record for ethica_id 5699 based on 'ignore' flag.\n",
      "→ Skipping creation of record for ethica_id 10581 based on 'ignore' flag.\n",
      "→ Skipping creation of record for ethica_id 9321 based on 'ignore' flag.\n"
     ]
    }
   ],
   "source": [
    "# Create new users based on records found in linkage file\n",
    "create_sql = \"\"\"\n",
    "    INSERT INTO portal_dev.ethica_assignments (interact_id, ethica_id, study_id)\n",
    "    VALUES (%s, %s, %s);           \n",
    "    \"\"\"\n",
    "#log(f\"Participant study map: {participant_study}\")\n",
    "\n",
    "# Open a database session\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    # read through each line of the linkage csv\n",
    "    with open(linkage_file,'r') as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        # for each line, determine whether the record already exists\n",
    "        for record in reader:\n",
    "            # figure out whether to update, insert, or delete, based on CSV record\n",
    "            ignore_user_rec = 'ignore' in record['data_disposition']\n",
    "            real_user = not 'cull' in record['data_disposition']\n",
    "            iid = record['interact_id']\n",
    "            eid = record['ethica_id']\n",
    "            if ignore_user_rec:\n",
    "                log(f\"Skipping creation of record for ethica_id {eid} based on 'ignore' flag.\")\n",
    "                continue\n",
    "            if not validate_eid(eid, logfailures=False): # ignore non-Ethica users\n",
    "                #log(f\"Skipping linkage record for IID {iid} - {eid} is not a valid Ethica ID\")\n",
    "                continue\n",
    "            #start_date = record['sd_start_1']\n",
    "            #end_date = record['sd_end_1']\n",
    "            if not real_user: # confirm user doesn't already exist\n",
    "                log(f\"Skipping creation of participation record for ethica test user {eid}\")\n",
    "                continue\n",
    "            if isinstance(ethica_study_id, int):\n",
    "                assign_study = ethica_study_id\n",
    "            elif eid in participant_study:\n",
    "                assign_study = participant_study[eid]\n",
    "            else:\n",
    "                log(f\"Can't determine ethica_study_id for ethica_id {eid}. Skipping user.\")\n",
    "                continue\n",
    "            sql = f\"\"\"SELECT count(1) as count from portal_dev.ethica_assignments\n",
    "                      WHERE interact_id = {iid} AND study_id = {assign_study};\"\"\"\n",
    "            cur.execute(sql)\n",
    "            row = cur.fetchone()\n",
    "            if row['count'] == 0:   \n",
    "                cur.execute(create_sql, (iid, eid, assign_study))\n",
    "                if cur.rowcount == 1:\n",
    "                    log(f\"Interact User {iid} had no participation record for study {assign_study}. Created.\")\n",
    "                else:\n",
    "                    log(f\"Problem trying to create participation record for user {iid} in study {assign_study}\")\n",
    "                #log(f\"Creating user {iid}, {eid}, {assign_study}, {start_date}, {end_date}\")\n",
    "            else:\n",
    "                log(f\"INTERACT USER {iid} ALREADY EXISTS IN STUDY {assign_study}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Targets\n",
    "\n",
    "The preliminary ingest for {{city_name}} Wave 1 will create the following tables in the level_0 schema:\n",
    "\n",
    "  - {{city_prefix}}-w1-eth-gps-raw-TOXIC\n",
    "  - {{city_prefix}}-w1-eth-xls-raw-TOXIC\n",
    "  - {{city_prefix}}-w1-eth-xls-delduplrec (raw xls with all rec-time duplicates removed)\n",
    "  - {{city_prefix}}-w1-eth-xls-delconflrec (raw xls with all rec-time conflicts removed)\n",
    "  - {{city_prefix}}-w1-eth-gps-delduplsat (raw gps with all sat-time duplicates removed)\n",
    "  - {{city_prefix}}-w1-eth-gps-delduplrec (raw gps with all rec-time duplicates removed)\n",
    "  - {{city_prefix}}-w1-eth-gps-delconflsat (raw gps with all sat-time conflicts removed)\n",
    "  - {{city_prefix}}-w1-eth-gps-delconflrec (raw gps with all rec-time conflicts removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gps_raw_TOXIC\n",
    "\n",
    "Ideally, we want to use the psql COPY command, since it has been\n",
    "optimized for fast loading, but the target telemetry table and the\n",
    "incoming CSV file have different column names. We *COULD* just rename \n",
    "the columns in the CSV file, but that's a manual step that shouldn't\n",
    "be embedded into the process.\n",
    "\n",
    "So instead, we'll load the data into a temporary table, and then transfer it from there into the target table and match the records to their interact_ids at the same time. This method will more or less double the ingest time, but having a reliable ingest process that can be fully documented, without manual interventions, seems like the more robust path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T04:38:08.812581Z",
     "start_time": "2020-10-29T04:38:08.793814Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# get a list of ethica_ids that are supposed to be culled from the ingest\n",
    "def get_ids_to_be_culled(csvfilepath):\n",
    "    culls = set([])\n",
    "    with open(csvfilepath,'r') as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        # for each line, determine whether the record already exists\n",
    "        for record in reader:\n",
    "            #if 'cull' in record['data_disposition'] and not 'ignore' in record['data_disposition']:\n",
    "                # a record that is both culled and ignored would not have been counted in the expected row count\n",
    "            if 'cull' in record['data_disposition']:    \n",
    "                culls.add(record['ethica_id'])\n",
    "    if culls:\n",
    "        log(f\"Ethica IDs to be culled as per linkage file:\")\n",
    "        log(f\"{culls}\")\n",
    "    else:\n",
    "        log(\"Linkage file includes no cull requests.\")\n",
    "    return culls\n",
    "\n",
    "def get_ids_to_be_ignored(csvfilepath):\n",
    "    ignores = set([])\n",
    "    with open(csvfilepath,'r') as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        # for each line, determine whether the record already exists\n",
    "        for record in reader:\n",
    "            #if 'cull' in record['data_disposition'] and not 'ignore' in record['data_disposition']:\n",
    "                # a record that is both culled and ignored would not have been counted in the expected row count\n",
    "            if 'ignore' in record['data_disposition']:    \n",
    "                ignores.add(record['ethica_id'])\n",
    "    if ignores:\n",
    "        log(f\"Ethica IDs to be ignored as per linkage file:\")\n",
    "        log(f\"{ignores}\")\n",
    "    else:\n",
    "        log(\"Linkage file includes no ignore requests.\")\n",
    "    return ignores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T04:38:34.207484Z",
     "start_time": "2020-10-29T04:38:34.164527Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Function to create the temporary incoming table and load the raw GPS data into it\n",
    "def load_raw_CSV_data(csvfilepaths, schema, tmptablename, tmpsqlvars, desttablename, destsqlvars, transfersql):\n",
    "    log(f\"Loading files '{csvfilepaths}' into table '{tmptablename}' of schema '{schema}'\")\n",
    "    with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "        cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "\n",
    "        # Create the temporary onboarding table\n",
    "        fulltmptablename = f\"{schema}.{tmptablename}\"\n",
    "        sql = f\"\"\"\n",
    "            DROP TABLE IF EXISTS {fulltmptablename}; \n",
    "            CREATE TABLE {fulltmptablename} (\n",
    "                {tmpsqlvars}\n",
    "                );\n",
    "                \"\"\"\n",
    "        log(f\"Creating temp ingest table {tmptablename}\")\n",
    "        cur.execute(sql)\n",
    "        # now add a comment describing table's purpose\n",
    "        cur.execute(f\"COMMENT ON TABLE {fulltmptablename} IS 'Temporary table for raw data ingest.';\")\n",
    "        \n",
    "        \n",
    "        # Now create the final destination table\n",
    "        # Create the final destination table\n",
    "        fulldesttablename = f\"{schema}.{desttablename}\"\n",
    "        sql = f\"\"\"\n",
    "            DROP TABLE IF EXISTS {fulldesttablename} CASCADE; \n",
    "            CREATE TABLE {fulldesttablename} (\n",
    "                {destsqlvars}\n",
    "                )\n",
    "                \"\"\"\n",
    "        log(f\"Creating destination table {fulldesttablename}\")\n",
    "        cur.execute(sql)\n",
    "\n",
    "        \n",
    "        # With tables created, we can now load the data from the CSV files\n",
    "        for csvfilepath in csvfilepaths:\n",
    "            log(f\"Ingesting raw CSV from {csvfilepath}\")\n",
    "            with open(csvfilepath, 'r') as f:\n",
    "                # Notice that we don't need the `csv` module.\n",
    "                next(f) # Skip the header row because copy_from doesn't want it\n",
    "                cur.copy_from(f, fulltmptablename, sep=',')\n",
    "\n",
    "        # Now collect some basic stats and validate the loaded raw data\n",
    "        log(f\"Checking success of raw data load\")\n",
    "        rowcount = 0\n",
    "        for csvfilepath in csvfilepaths:\n",
    "            with open(csvfilepath,'r') as fh:\n",
    "                for line in fh:\n",
    "                    rowcount += 1\n",
    "            rowcount -= 1 #don't count the header row\n",
    "        log(f\"Expecting {rowcount:,} lines in table\")      \n",
    "        sql = f\"\"\"SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "                  FROM (\n",
    "                         SELECT COUNT(1) as num_recs\n",
    "                         FROM {fulltmptablename}\n",
    "                         GROUP BY user_id\n",
    "                       ) as records_per_user\n",
    "                  \"\"\"\n",
    "        cur.execute(sql)\n",
    "        row = cur.fetchone()\n",
    "        num_raw_recs = row['num_recs']\n",
    "        num_raw_users = row['num_users']\n",
    "        log(f\"Ingested {num_raw_recs:,} records across {num_raw_users:,} users.\")\n",
    "        if num_raw_recs == rowcount:\n",
    "            log(\"Raw data ingest appears successful.\")\n",
    "            conn.commit()\n",
    "        else:\n",
    "            log(f\"ERROR: INGESTED ROW COUNT ({num_raw_recs}) DOES NOT MATCH SOURCE FILE ({rowcount})\")\n",
    "            return\n",
    "              \n",
    "        # And finally, we can transfer the data from the staging table into the final location\n",
    "        log(f\"Matching ethica_ids to interact_ids and transfering records into destination table\")\n",
    "        cur.execute(transfer_sql)\n",
    "\n",
    "        # And collect some basic stats to validate the ingested data\n",
    "        log(f\"Checking success of ingest\")\n",
    "        sql = f\"\"\"SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "                  FROM (\n",
    "                         SELECT COUNT(1) as num_recs\n",
    "                         FROM {fulldesttablename}\n",
    "                         GROUP BY iid\n",
    "                       ) as records_per_user\n",
    "                  \"\"\"\n",
    "        cur.execute(sql)\n",
    "        row = cur.fetchone()\n",
    "        num_final_recs = row['num_recs']\n",
    "        num_final_users = row['num_users']\n",
    "        \n",
    "        # count the number of records for which there are no matching interact_ids\n",
    "        missing_sql = f\"\"\"\n",
    "            SELECT count(1) as num_missing_users, sum(num_recs) as total_missing_recs, min(interact_id)\n",
    "            FROM (\n",
    "                SELECT count(1) as num_recs, min(interact_id) as interact_id, min(user_id), min(ethica_email)\n",
    "                FROM \n",
    "                   portal_dev.ethica_assignments asgn\n",
    "                   RIGHT OUTER JOIN {fulltmptablename} raw\n",
    "                   ON asgn.ethica_id = raw.user_id\n",
    "                GROUP BY user_id\n",
    "            ) recs_per_unmatched_user\n",
    "            WHERE interact_id IS NULL;\n",
    "            \"\"\"\n",
    "        cur.execute(missing_sql)\n",
    "        row = cur.fetchone()\n",
    "        num_missing_recs = int(row['total_missing_recs'] or 0) #assign 0 if no records match\n",
    "        num_missing_users = int(row['num_missing_users'] or 0) #assign 0 if no records match\n",
    "        log(f\"Identified {num_missing_recs:,} records across {num_missing_users:,} users for whom interact_id is not known.\")\n",
    "        \n",
    "        # Report the success, partial success, or failure of the ingest\n",
    "        log(f\"Transfered {num_final_recs:,} records for {num_final_users:,} users.\")\n",
    "        return\n",
    "    \n",
    "        if num_raw_recs == num_final_recs:\n",
    "            log(\"Data transfer and ingest operation complete. All records ingested.\")\n",
    "            conn.commit()\n",
    "        elif num_raw_recs == num_final_recs + num_missing_recs:\n",
    "            log(f\"Data transfer and ingest operation complete. All records accounted for, but {num_missing_users:,} unknown users.\")\n",
    "            conn.commit()\n",
    "        else:\n",
    "            log(\"ERROR: TRANSFERED ROW COUNT DOES NOT MATCH STAGING TABLE\")\n",
    "            #log(f\"Expected {num_missing_recs} missing recs but found {} to be missing.\")\n",
    "   \n",
    "        \"\"\"    \n",
    "        A mismatched row count alone is not indicative of an ingest problem because some user data\n",
    "        is suppressed by design. Any user marked \"cull\" in the linkage table will be ignored, even\n",
    "        though they might have associated data in the telemetry file. (These are test users, for the \n",
    "        most part, but could also be problematic cases identified during ingest.)\n",
    "        \n",
    "        To create a more robust and accurate verification pass, we need to:\n",
    "        - have a list of all users who are being actively culled\n",
    "        - have a count of telemetry rows associated with each such culled account\n",
    "          - can count with join against user_category\n",
    "        - then compare the ingested raw ingest row count with the final ingest PLUS the culled rows\n",
    "        \"\"\"\n",
    "            \n",
    "        data = [ ['num_recs', num_final_recs], ['num_users', num_final_users], ]\n",
    "        print(f\"\\nFigure: Counts for {fulldesttablename}\")\n",
    "        print(tabulate(data, floatfmt=',.0f', stralign='right' ))\n",
    "        \n",
    "        \n",
    "        # If there were some unmatched user_ids, list them so operator can investigate\n",
    "        if num_missing_recs:\n",
    "            problems_sql = f\"\"\"\n",
    "                SELECT count(1) as num_recs, \n",
    "                       min(user_id) as user_id\n",
    "                FROM portal_dev.ethica_assignments asgn\n",
    "                   RIGHT OUTER JOIN {fulltmptablename} raw\n",
    "                   ON asgn.ethica_id = raw.user_id\n",
    "                WHERE interact_id IS NULL\n",
    "                GROUP BY user_id;\n",
    "                \"\"\"\n",
    "            print(f\"\\nFigure: Unmatched user_ids from {tmptablename}\")\n",
    "            cur.execute(problems_sql)\n",
    "            rows = cur.fetchall()\n",
    "            print(tabulate(rows, headers='keys'))\n",
    "            print(f\"Total Unmatched Rows: {num_missing_recs:,}\")\n",
    "#        else:\n",
    "#            log(\"Record count in CSV matches record count of ingested table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T18:56:03.260677Z",
     "start_time": "2020-10-28T18:46:52.439060Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Ethica IDs to be culled as per linkage file:\n",
      "→ {'7820', '6402', '7441', '10581', '6091', '6227', '8889', '7712', '8236', '5795', '5930', '6044', '5597', '9321', '5819', '5699', '9409', '9005', '6376', '6377', '5974', '5677', '5891', '5865'}\n",
      "→ Ethica IDs to be ignored as per linkage file:\n",
      "→ {'10581', '5992', '5582', '9026', '5695', '9321', '9000', '5699'}\n",
      "→ Loading files '{'/home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/gps.csv': 395, '/home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/gps.csv': 396}' into table 'tmpgps' of schema 'level_0'\n",
      "→ Creating temp ingest table tmpgps\n",
      "→ Creating destination table level_0.mtl_w1_eth_gps_raw_TOXIC\n",
      "→ Ingesting raw CSV from /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/gps.csv\n",
      "→ Ingesting raw CSV from /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/gps.csv\n",
      "→ Checking success of raw data load\n",
      "→ Expecting 84,086,076 lines in table\n",
      "→ Ingested 84,086,076 records across 553 users.\n",
      "→ Raw data ingest appears successful.\n",
      "→ Matching ethica_ids to interact_ids and transfering records into destination table\n",
      "→ Checking success of ingest\n",
      "→ Identified 450,178 records across 6 users for whom interact_id is not known.\n",
      "→ Transfered 83,615,866 records for 545 users.\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameters for loading the GPS table data and then load it\n",
    "telemetryfilename = \"gps.csv\"\n",
    "fullcsvpath = os.path.join(telemetrydir, telemetryfilename)\n",
    "tmptablename = \"tmpgps\"\n",
    "desttablename = f\"{city_prefix}_w1_eth_gps_raw_TOXIC\"\n",
    "\n",
    "ids_to_cull = get_ids_to_be_culled(linkage_file)\n",
    "ids_to_ignore = get_ids_to_be_ignored(linkage_file)\n",
    "\n",
    "# make sure we cull any data from both cull records and ignore records\n",
    "ids_to_cull.update(ids_to_ignore)\n",
    "\n",
    "tmpsqlvars = \"\"\"\n",
    "    user_id BIGINT NOT NULL,\n",
    "    date TEXT,\n",
    "    device_id TEXT NOT NULL,\n",
    "    record_time TIMESTAMP WITH TIME ZONE NOT NULL,\n",
    "    timestamp TEXT,\n",
    "    accu DOUBLE PRECISION,\n",
    "    alt DOUBLE PRECISION,\n",
    "    bearing DOUBLE PRECISION,\n",
    "    lat DOUBLE PRECISION NOT NULL,\n",
    "    lon DOUBLE PRECISION NOT NULL,\n",
    "    provider TEXT,\n",
    "    satellite_time TIMESTAMP WITH TIME ZONE,\n",
    "    speed DOUBLE PRECISION\n",
    "    \"\"\"\n",
    "\n",
    "destsqlvars = \"\"\"\n",
    "    iid BIGINT NOT NULL,  -- interact_id\n",
    "    record_time TIMESTAMP WITH TIME ZONE NOT NULL, -- participant's UTC time, to millisec, from phone clock\n",
    "    satellite_time TIMESTAMP WITH TIME ZONE NOT NULL, -- timestamp taken from satellite data\n",
    "    lat DOUBLE PRECISION NOT NULL,\n",
    "    lon DOUBLE PRECISION NOT NULL,\n",
    "    speed DOUBLE PRECISION DEFAULT 'NaN',\n",
    "    course DOUBLE PRECISION DEFAULT 'NaN',\n",
    "    alt DOUBLE PRECISION DEFAULT 'NaN',\n",
    "    accu DOUBLE PRECISION DEFAULT 'NaN',\n",
    "    provider TEXT DEFAULT ''\n",
    "    \"\"\"\n",
    "\n",
    "transfer_sql = f\"\"\"\n",
    "   INSERT INTO {db_schema}.{desttablename} (iid,record_time,satellite_time,lat,lon,speed,course,alt,accu,provider)\n",
    "        SELECT asgn.interact_id,\n",
    "                raw.record_time,\n",
    "                raw.satellite_time,\n",
    "                raw.lat,\n",
    "                raw.lon,\n",
    "                raw.speed,\n",
    "                raw.bearing,\n",
    "                raw.alt,\n",
    "                raw.accu,\n",
    "                raw.provider\n",
    "        FROM {db_schema}.{tmptablename} raw \n",
    "            INNER JOIN portal_dev.ethica_assignments AS asgn\n",
    "            ON raw.user_id = asgn.ethica_id AND asgn.study_id in {tuple(ethica_study_id)}\n",
    "        WHERE raw.user_id not in {tuple(ids_to_cull)}\n",
    "        \"\"\"\n",
    "\n",
    "telemetryfiles = {os.path.join(telemetrydir, 'gps.csv'):395, \n",
    "                 os.path.join(telemetrydir, 'gps.csv').replace('_en_', '_fr_'):396}\n",
    "load_raw_CSV_data(telemetryfiles, db_schema, tmptablename, tmpsqlvars, desttablename, destsqlvars, transfer_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T18:59:23.629459Z",
     "start_time": "2020-10-28T18:59:05.872960Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Ethica IDs to be culled as per linkage file:\n",
      "→ {'7820', '6402', '7441', '10581', '6091', '6227', '8889', '7712', '8236', '5795', '5930', '6044', '5597', '9321', '5819', '5699', '9409', '9005', '6376', '6377', '5974', '5677', '5891', '5865'}\n",
      "→ Ethica IDs to be ignored as per linkage file:\n",
      "→ {'10581', '5992', '5582', '9026', '5695', '9321', '9000', '5699'}\n",
      "→ There were 24 ethica_ids culled from the ingest.\n",
      "→ There were 8 ethica_ids ignored from the ingest.\n",
      "→ All user_ids expected to have data missing: {'7820', '6402', '7441', '10581', '6091', '5992', '6227', '8889', '7712', '8236', '5795', '5930', '6044', '5597', '9321', '5695', '5819', '5699', '9409', '9005', '6376', '5582', '6377', '5974', '9000', '5677', '5891', '9026', '5865'}\n",
      "→ Ingest passes basic validation.\n",
      "\n",
      "Figure: Validating table 'level_0.mtl_w1_eth_gps_raw_TOXIC'\n",
      "\n",
      "----------------------  ----------\n",
      "     total_raw_samples  84,086,076\n",
      "        culled_samples     470,210\n",
      "expected_final_samples  83,615,866\n",
      "  actual_final_samples  83,615,866\n",
      "----------------------  ----------\n"
     ]
    }
   ],
   "source": [
    "# Validate the ingested table\n",
    "# Count the number of ingested records and compare with expected number\n",
    "desttablename = f\"{city_prefix}_w1_eth_gps_raw_TOXIC\"\n",
    "fulldesttablename = f\"{db_schema}.{desttablename}\"\n",
    "\n",
    "# count records produced by users who were not ingested\n",
    "# First, generate the list of culled users\n",
    "#culled_eids = set([])\n",
    "#with open(linkage_file,'r') as fh:\n",
    "#    reader = csv.DictReader(fh)\n",
    "    # for each line, determine whether the record already exists\n",
    "#    for record in reader:\n",
    "        #if 'cull' in record['data_disposition'] and not 'ignore' in record['data_disposition']:\n",
    "            # a record that is both culled and ignored would not have been counted in the expected row count\n",
    "#        if 'cull' in record['data_disposition']:    \n",
    "#            culled_eids.add(record['ethica_id'])\n",
    "culled_eids = get_ids_to_be_culled(linkage_file)\n",
    "ignored_eids = get_ids_to_be_ignored(linkage_file)\n",
    "log(f\"There were {len(culled_eids)} ethica_ids culled from the ingest.\")\n",
    "#log(f\"Culled IDs: {culled_eids}\")\n",
    "log(f\"There were {len(ignored_eids)} ethica_ids ignored from the ingest.\")\n",
    "#log(f\"Ignored IDs: {ignored_eids}\")\n",
    "\n",
    "# for the purposes of which ids are expected to have absent data, we include the ignored ids as well as culled\n",
    "culled_eids.update(ignored_eids)\n",
    "log(f\"All user_ids expected to have data missing: {culled_eids}\")\n",
    "\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    \n",
    "    # Next, count how many records are associated with those culled ids\n",
    "    sql = f\"\"\"\n",
    "           SELECT COUNT(1) AS total_samples, \n",
    "                  SUM(1) FILTER (WHERE user_id IN %s) AS num_culled_samples\n",
    "           FROM {db_schema}.{tmptablename}\"\"\"\n",
    "    cur.execute(sql, (tuple(culled_eids),))\n",
    "    row = cur.fetchone()\n",
    "    num_culled_samples = row['num_culled_samples'] if row['num_culled_samples'] else 0\n",
    "    total_raw_samples = row['total_samples']\n",
    "    \n",
    "    # Count number of actual records ingested into final table\n",
    "    sql = f\"\"\"SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "              FROM (\n",
    "                     SELECT COUNT(1) as num_recs\n",
    "                     FROM {fulldesttablename}\n",
    "                     GROUP BY iid\n",
    "                   ) as records_per_user\n",
    "              \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['total_raw_samples', total_raw_samples], \n",
    "            ['culled_samples', num_culled_samples],   \n",
    "            ['expected_final_samples', total_raw_samples - num_culled_samples],\n",
    "            ['actual_final_samples', row['num_recs']], ]\n",
    "\n",
    "    \n",
    "    if total_raw_samples - num_culled_samples == row['num_recs']:\n",
    "        log(\"Ingest passes basic validation.\")\n",
    "    else:\n",
    "        log(\"ERROR: INGEST VALIDATION FAILED\")\n",
    "        \n",
    "    print(f\"\\nFigure: Validating table '{fulldesttablename}'\\n\")\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xls_raw_TOXIC\n",
    "Proceeds as per the GPS table, but with accelerometry source file and column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T09:41:11.159061Z",
     "start_time": "2020-10-29T04:39:36.107417Z"
    },
    "code_folding": [
     12,
     24
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Ethica IDs to be culled as per linkage file:\n",
      "→ {'5699', '6091', '9409', '5974', '7441', '6227', '5819', '6044', '9321', '6376', '7820', '5795', '9005', '6402', '6377', '8236', '5677', '5891', '5865', '5930', '10581', '8889', '7712', '5597'}\n",
      "→ Ethica IDs to be ignored as per linkage file:\n",
      "→ {'5699', '5582', '5992', '9000', '9026', '10581', '9321', '5695'}\n",
      "→ Loading files '{'/home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/accelerometer.csv': 395, '/home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/accelerometer.csv': 396}' into table 'tmpxl' of schema 'level_0'\n",
      "→ Creating temp ingest table tmpxl\n",
      "→ Creating destination table level_0.mtl_w1_eth_xls_raw_TOXIC\n",
      "→ Ingesting raw CSV from /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_en_01/raw/accelerometer.csv\n",
      "→ Ingesting raw CSV from /home/jeffs/projects/def-dfuller/interact/permanent_archive/Montreal/Wave1/Ethica/montreal_fr_01/raw/accelerometer.csv\n",
      "→ Checking success of raw data load\n",
      "→ Expecting 3,459,362,823 lines in table\n",
      "→ Ingested 3,459,362,823 records across 558 users.\n",
      "→ Raw data ingest appears successful.\n",
      "→ Matching ethica_ids to interact_ids and transfering records into destination table\n",
      "→ Checking success of ingest\n",
      "→ Identified 18,944,568 records across 11 users for whom interact_id is not known.\n",
      "→ Transfered 3,438,057,266 records for 545 users.\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameters for loading the XL table data and then load it\n",
    "telemetryfilename = \"accelerometer.csv\"\n",
    "fullcsvpath = os.path.join(telemetrydir, telemetryfilename)\n",
    "tmptablename = \"tmpxl\"\n",
    "desttablename = f\"{city_prefix}_w1_eth_xls_raw_TOXIC\"\n",
    "\n",
    "ids_to_cull = get_ids_to_be_culled(linkage_file)\n",
    "ids_to_ignore = get_ids_to_be_ignored(linkage_file)\n",
    "\n",
    "# make sure we cull any data from both cull records and ignore records\n",
    "ids_to_cull.update(ids_to_ignore)\n",
    "\n",
    "tmpsqlvars = \"\"\"\n",
    "    user_id BIGINT NOT NULL,\n",
    "    date TEXT,\n",
    "    device_id TEXT NOT NULL,\n",
    "    record_time TIMESTAMP WITH TIME ZONE NOT NULL,\n",
    "    timestamp TEXT,\n",
    "    accu DOUBLE PRECISION,\n",
    "    x_axis DOUBLE PRECISION NOT NULL,\n",
    "    y_axis DOUBLE PRECISION NOT NULL,\n",
    "    z_axis DOUBLE PRECISION NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "destsqlvars = \"\"\"\n",
    "    iid BIGINT NOT NULL,   -- interact_id\n",
    "    record_time TIMESTAMP WITH TIME ZONE NOT NULL, -- participant's UTC time, to millisec \n",
    "    x DOUBLE PRECISION NOT NULL,\n",
    "    y DOUBLE PRECISION NOT NULL,\n",
    "    z DOUBLE PRECISION NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "transfer_sql = f\"\"\"\n",
    "    INSERT INTO {db_schema}.{desttablename} (iid,record_time,x,y,z)\n",
    "    SELECT asgn.interact_id,\n",
    "        raw.record_time,\n",
    "        raw.x_axis,\n",
    "        raw.y_axis,\n",
    "        raw.z_axis\n",
    "    FROM {db_schema}.{tmptablename} raw \n",
    "        INNER JOIN portal_dev.ethica_assignments asgn\n",
    "        ON raw.user_id = asgn.ethica_id AND asgn.study_id in {tuple(ethica_study_id)}\n",
    "        WHERE raw.user_id not in {tuple(ids_to_cull)}\n",
    "        \"\"\"\n",
    "\n",
    "telemetryfiles = {os.path.join(telemetrydir, 'accelerometer.csv'):395, \n",
    "                 os.path.join(telemetrydir, 'accelerometer.csv').replace('_en_', '_fr_'):396}\n",
    "\n",
    "load_raw_CSV_data(telemetryfiles, db_schema, tmptablename, tmpsqlvars, desttablename, destsqlvars, transfer_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T16:29:35.309288Z",
     "start_time": "2020-10-29T16:13:17.685895Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Validating mtl_w1_eth_xls_raw_TOXIC...\n",
      "→ Ethica IDs to be culled as per linkage file:\n",
      "→ {'5699', '6091', '9409', '5974', '7441', '6227', '5819', '6044', '9321', '6376', '7820', '5795', '9005', '6402', '6377', '8236', '5677', '5891', '5865', '5930', '10581', '8889', '7712', '5597'}\n",
      "→ Ethica IDs to be ignored as per linkage file:\n",
      "→ {'5699', '5582', '5992', '9000', '9026', '10581', '9321', '5695'}\n",
      "→ There were 24 ethica_ids culled from the ingest.\n",
      "→ There were 8 ethica_ids ignored from the ingest.\n",
      "→ Ingest passes basic validation.\n",
      "\n",
      "Figure: Validating table 'level_0.mtl_w1_eth_xls_raw_TOXIC'\n",
      "\n",
      "----------------------  -------------\n",
      "     total_raw_samples  3,459,362,823\n",
      "        culled_samples     21,305,557\n",
      "expected_final_samples  3,438,057,266\n",
      "  actual_final_samples  3,438,057,266\n",
      "----------------------  -------------\n"
     ]
    }
   ],
   "source": [
    "# Validate the ingested table\n",
    "# Count the number of ingested records and compare with expected number\n",
    "desttablename = f\"{city_prefix}_w1_eth_xls_raw_TOXIC\"\n",
    "fulldesttablename = f\"{db_schema}.{desttablename}\"\n",
    "\n",
    "log(f\"Validating {desttablename}...\")\n",
    "# count records produced by users who were not ingested\n",
    "# First, generate the list of users whose telemetry is being culled\n",
    "#culled_eids = set([])\n",
    "#with open(linkage_file,'r') as fh:\n",
    "#    reader = csv.DictReader(fh)\n",
    "    # for each line, determine whether the record already exists\n",
    "#    for record in reader:\n",
    "#        if 'cull' in record['data_disposition'] and not 'ignore' in record['data_disposition']:\n",
    "            # a record that is both culled and ignored would not have been counted in the expected row count\n",
    "#            culled_eids.add(record['ethica_id'])\n",
    "culled_eids = get_ids_to_be_culled(linkage_file)\n",
    "ignored_eids = get_ids_to_be_ignored(linkage_file)\n",
    "log(f\"There were {len(culled_eids)} ethica_ids culled from the ingest.\")\n",
    "#log(f\"Culled IDs: {culled_eids}\")\n",
    "log(f\"There were {len(ignored_eids)} ethica_ids ignored from the ingest.\")\n",
    "#log(f\"Ignored IDs: {ignored_eids}\")\n",
    "\n",
    "# for the purposes of which ids are expected to have absent data, we include the ignored ids as well as culled\n",
    "culled_eids.update(ignored_eids)\n",
    "\n",
    "\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "\n",
    "    # Next, count how many records are associated with those culled ids\n",
    "    sql = f\"\"\"\n",
    "           SELECT COUNT(1) AS total_samples, \n",
    "                  SUM(1) FILTER (WHERE user_id IN %s) AS num_culled_samples\n",
    "           FROM {db_schema}.{tmptablename}\"\"\"\n",
    "    cur.execute(sql, (tuple(culled_eids),))\n",
    "    row = cur.fetchone()\n",
    "    num_culled_samples = row['num_culled_samples'] if row['num_culled_samples'] else 0\n",
    "    total_raw_samples = row['total_samples']\n",
    "    \n",
    "    # Count number of actual records ingested into final table\n",
    "    sql = f\"\"\"SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "              FROM (\n",
    "                     SELECT COUNT(1) as num_recs\n",
    "                     FROM {fulldesttablename}\n",
    "                     GROUP BY iid\n",
    "                   ) as records_per_user\n",
    "              \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['total_raw_samples', total_raw_samples], \n",
    "            ['culled_samples', num_culled_samples],   \n",
    "            ['expected_final_samples', total_raw_samples - num_culled_samples],\n",
    "            ['actual_final_samples', row['num_recs']], ]\n",
    "\n",
    "    \n",
    "    if total_raw_samples - num_culled_samples == row['num_recs']:\n",
    "        log(\"Ingest passes basic validation.\")\n",
    "    else:\n",
    "        log(\"ERROR: INGEST VALIDATION FAILED\")\n",
    "        \n",
    "    print(f\"\\nFigure: Validating table '{fulldesttablename}'\\n\")\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing population of both tables\n",
    "As a final validation, verify that the GPS and XLS raw tables both have data from the same users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T16:46:07.678120Z",
     "start_time": "2020-10-29T16:35:47.516608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure: Montreal users with data present in only one table\n",
      "\n",
      "No mismatches found.\n"
     ]
    }
   ],
   "source": [
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "   \n",
    "    mismatch_sql = f\"\"\"\n",
    "        SET SCHEMA '{db_schema}';\n",
    "        DROP TABLE IF EXISTS tmpgpsiids;\n",
    "        DROP TABLE IF EXISTS tmpxlsiids;\n",
    "        CREATE TABLE tmpgpsiids AS SELECT DISTINCT iid FROM {city_prefix}_w1_eth_gps_raw_toxic ;\n",
    "        CREATE TABLE tmpxlsiids AS SELECT DISTINCT iid FROM {city_prefix}_w1_eth_xls_raw_toxic ;\n",
    "        SELECT tmpgpsiids.iid AS gps_iid, tmpxlsiids.iid AS xls_iid \n",
    "        FROM tmpgpsiids \n",
    "             RIGHT OUTER JOIN tmpxlsiids \n",
    "             ON tmpgpsiids.iid = tmpxlsiids.iid \n",
    "        WHERE tmpgpsiids.iid IS NULL \n",
    "           OR tmpxlsiids.iid IS NULL;\n",
    "        \"\"\"\n",
    "    \n",
    "    print(f\"\\nFigure: {city_name} users with data present in only one table\\n\")\n",
    "    cur.execute(mismatch_sql)\n",
    "    rows = cur.fetchall()\n",
    "    if rows:\n",
    "        print(tabulate(rows, headers='keys', stralign='right'))\n",
    "    else:\n",
    "        print('No mismatches found.')\n",
    "\n",
    "    # Interact_id 302562672 is known to have no GPS data for SSK\n",
    "    # Interact_id 201680208 is known to have no GPS data for VAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table *-xs-delduplrec \n",
    "This table will be extracted from the raw XLS data, with all record_time **duplicates** removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T22:11:01.238260Z",
     "start_time": "2020-10-29T17:23:42.669852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Creating mtl_w1_eth_xls_delduplrec from scratch...\n",
      "→ Done\n",
      "\n",
      "Figure: Basic counts for table mtl_w1_eth_xls_delduplrec\n",
      "\n",
      "---------  -------------\n",
      " num_recs  3,012,538,959\n",
      "num_users            545\n",
      "---------  -------------\n"
     ]
    }
   ],
   "source": [
    "tablename = f\"{city_prefix}_w1_eth_xls_delduplrec\"\n",
    "sourcetable = f\"{city_prefix}_w1_eth_xls_raw_TOXIC\"\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    log(f\"Creating {tablename} from scratch...\")\n",
    "    sql = f\"\"\"\n",
    "        DROP TABLE IF EXISTS {db_schema}.{tablename};\n",
    "        CREATE TABLE {db_schema}.{tablename}\n",
    "        AS\n",
    "            SELECT iid, record_time, x, y, z\n",
    "            FROM (\n",
    "                SELECT count(1) as numrows, \n",
    "                       iid, \n",
    "                       record_time,\n",
    "                       min(x) as x,\n",
    "                       min(y) as y,\n",
    "                       min(z) as z\n",
    "                FROM {db_schema}.{sourcetable}\n",
    "                GROUP BY iid, record_time\n",
    "                ) as count_collisions\n",
    "            WHERE numrows = 1; -- there are no duplicates at all\n",
    "        CREATE UNIQUE INDEX {tablename}_idx ON {db_schema}.{tablename} (iid, record_time);\n",
    "            \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    log(f\"Done\")\n",
    "    \n",
    "    # Report basic stats on the newly created table\n",
    "    print(f\"\\nFigure: Basic counts for table {tablename}\\n\")\n",
    "    sql = f\"\"\"\n",
    "        SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {db_schema}.{tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table *-gps-delduplrec \n",
    "This table will be extracted from the raw GPS data, with all record_time **duplicates** removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T22:13:23.228323Z",
     "start_time": "2020-10-29T22:11:01.281060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Creating table mtl_w1_eth_gps_delduplrec from scratch...\n",
      "→ Done\n",
      "\n",
      "Figure: Basic counts for table mtl_w1_eth_gps_delduplrec\n",
      "\n",
      "---------  ----------\n",
      " num_recs  27,800,268\n",
      "num_users         545\n",
      "---------  ----------\n"
     ]
    }
   ],
   "source": [
    "tablename = f'{city_prefix}_w1_eth_gps_delduplrec'\n",
    "sourcetable = f\"{city_prefix}_w1_eth_gps_raw_TOXIC\"\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    log(f\"Creating table {tablename} from scratch...\")\n",
    "    sql = f\"\"\"\n",
    "        SET SCHEMA '{db_schema}';\n",
    "        DROP TABLE IF EXISTS {tablename};\n",
    "        CREATE TABLE {tablename}\n",
    "        AS\n",
    "            SELECT iid, record_time, satellite_time, minlat as lat, minlon as lon\n",
    "            FROM (\n",
    "                SELECT count(1) as numrows, \n",
    "                       iid, \n",
    "                       record_time, \n",
    "                       min(satellite_time) as satellite_time,\n",
    "                       min(lat) as minlat, \n",
    "                       max(lat) as maxlat,\n",
    "                       min(lon) as minlon,\n",
    "                       max(lon) as maxlon\n",
    "                FROM {sourcetable}\n",
    "                GROUP BY iid, record_time\n",
    "                ) as count_collisions\n",
    "            WHERE numrows = 1; -- there are no duplicates at all\n",
    "            CREATE UNIQUE INDEX {tablename}_idx ON {tablename} (iid, record_time);\n",
    "            \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    log(f\"Done\")\n",
    "    \n",
    "    # Report basic stats on the newly created table\n",
    "    print(f\"\\nFigure: Basic counts for table {tablename}\\n\")\n",
    "    sql = f\"\"\"\n",
    "    SET SCHEMA '{db_schema}';\n",
    "    SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table *-gps-delconflrec \n",
    "This table will be extracted from the raw GPS data, with all record_time **conflicts** removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T22:15:11.318391Z",
     "start_time": "2020-10-29T22:13:23.232328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Creating table mtl_w1_eth_gps_delconflrec from scratch...\n",
      "→ Done\n",
      "\n",
      "Figure: Basic counts for table mtl_w1_eth_gps_delconflrec\n",
      "\n",
      "---------  ----------\n",
      " num_recs  28,065,265\n",
      "num_users         545\n",
      "---------  ----------\n"
     ]
    }
   ],
   "source": [
    "tablename = f'{city_prefix}_w1_eth_gps_delconflrec'\n",
    "sourcetable = f\"{city_prefix}_w1_eth_gps_raw_TOXIC\"\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    log(f\"Creating table {tablename} from scratch...\")\n",
    "    sql = f\"\"\"\n",
    "        SET SCHEMA '{db_schema}';\n",
    "        DROP TABLE IF EXISTS {tablename};\n",
    "        CREATE TABLE {tablename}\n",
    "        AS\n",
    "            SELECT iid, record_time, satellite_time, minlat as lat, minlon as lon\n",
    "            FROM (\n",
    "                SELECT count(1) as numrows, \n",
    "                       iid, \n",
    "                       record_time, \n",
    "                       min(satellite_time) as satellite_time,\n",
    "                       min(lat) as minlat, \n",
    "                       max(lat) as maxlat,\n",
    "                       min(lon) as minlon,\n",
    "                       max(lon) as maxlon\n",
    "                FROM {sourcetable}\n",
    "                GROUP BY iid, record_time\n",
    "                ) as count_collisions\n",
    "            WHERE numrows = 1 -- there are no duplicates at all\n",
    "               OR (minlon = maxlon AND minlat = maxlat); -- the duplicates are identical\n",
    "        CREATE UNIQUE INDEX {tablename}_idx ON {tablename} (iid, record_time);\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    log(f\"Done\")\n",
    "    \n",
    "    # Report basic stats on the newly created table\n",
    "    print(f\"\\nFigure: Basic counts for table {tablename}\\n\")\n",
    "    sql = f\"\"\"\n",
    "    SET SCHEMA '{db_schema}';\n",
    "    SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table *-xls-delconflrec \n",
    "This table will be extracted from the raw XL data, with all record_time **conflicts** removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T01:07:33.487791Z",
     "start_time": "2020-10-29T22:15:11.321795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Creating table mtl_w1_eth_xls_delconflrec from scratch...\n",
      "→ Done\n",
      "\n",
      "Figure: Basic counts for table mtl_w1_eth_xls_delconflrec\n",
      "\n",
      "---------  -------------\n",
      " num_recs  3,020,062,703\n",
      "num_users            545\n",
      "---------  -------------\n"
     ]
    }
   ],
   "source": [
    "tablename = f'{city_prefix}_w1_eth_xls_delconflrec'\n",
    "sourcetable = f\"{city_prefix}_w1_eth_xls_raw_TOXIC\"\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    log(f\"Creating table {tablename} from scratch...\")\n",
    "    sql = f\"\"\"\n",
    "        SET SCHEMA '{db_schema}';\n",
    "        DROP TABLE IF EXISTS {tablename};\n",
    "        CREATE TABLE {tablename}\n",
    "        AS\n",
    "            SELECT iid, record_time, minx as x, miny as y, minz as z\n",
    "            FROM (\n",
    "                SELECT count(1) as numrows, \n",
    "                       iid, \n",
    "                       record_time,\n",
    "                       min(x) as minx,\n",
    "                       max(x) as maxx,\n",
    "                       min(y) as miny,\n",
    "                       max(y) as maxy,\n",
    "                       min(z) as minz,\n",
    "                       max(z) as maxz\n",
    "                FROM {sourcetable}\n",
    "                GROUP BY iid, record_time\n",
    "                ) as count_collisions\n",
    "            WHERE numrows = 1 -- there are no duplicates at all\n",
    "               OR (minx = maxx AND miny = maxy AND minz = maxz); -- the duplicates are identical\n",
    "            CREATE UNIQUE INDEX {tablename}_idx ON {tablename} (iid, record_time);\n",
    "            \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    log(f\"Done\")\n",
    "    \n",
    "    # Report basic stats on the newly created table\n",
    "    print(f\"\\nFigure: Basic counts for table {tablename}\\n\")\n",
    "    sql = f\"\"\"\n",
    "    SET SCHEMA '{db_schema}';\n",
    "    SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table *-gps-delduplsat\n",
    "This table will be extracted from the raw GPS data, with all satellite_time **duplicates** removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T01:09:24.813534Z",
     "start_time": "2020-10-30T01:07:33.537487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Creating table mtl_w1_eth_gps_delduplsat from scratch...\n",
      "→ Done\n",
      "\n",
      "Figure: Basic counts for table mtl_w1_eth_gps_delduplsat\n",
      "\n",
      "---------  ----------\n",
      " num_recs  24,944,462\n",
      "num_users         544\n",
      "---------  ----------\n"
     ]
    }
   ],
   "source": [
    "tablename = f'{city_prefix}_w1_eth_gps_delduplsat'\n",
    "sourcetable = f\"{city_prefix}_w1_eth_gps_raw_TOXIC\"\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    log(f\"Creating table {tablename} from scratch...\")\n",
    "    sql = f\"\"\"\n",
    "        SET SCHEMA '{db_schema}';\n",
    "        DROP TABLE IF EXISTS {tablename};\n",
    "        CREATE TABLE {tablename}\n",
    "        AS\n",
    "            SELECT iid, record_time, satellite_time, minlat as lat, minlon as lon\n",
    "            FROM (\n",
    "                SELECT count(1) as numrows, \n",
    "                       iid, \n",
    "                       min(record_time) as record_time, \n",
    "                       satellite_time,\n",
    "                       min(lat) as minlat, \n",
    "                       max(lat) as maxlat,\n",
    "                       min(lon) as minlon,\n",
    "                       max(lon) as maxlon\n",
    "                FROM {sourcetable}\n",
    "                GROUP BY iid, satellite_time\n",
    "                ) as count_collisions\n",
    "            WHERE numrows = 1; -- there are no duplicates at all\n",
    "        CREATE UNIQUE INDEX {tablename}_idx ON {tablename} (iid, satellite_time);\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    log(f\"Done\")\n",
    "    \n",
    "    # Report basic stats on the newly created table\n",
    "    print(f\"\\nFigure: Basic counts for table {tablename}\\n\")\n",
    "    sql = f\"\"\"\n",
    "    SET SCHEMA '{db_schema}';\n",
    "    SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table *-gps-delconflsat\n",
    "This table will be extracted from the raw GPS data, with all satellite_time **conflicts** removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-30T01:11:13.347431Z",
     "start_time": "2020-10-30T01:09:24.816164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Creating table mtl_w1_eth_gps_delconflsat from scratch...\n",
      "→ Done\n",
      "\n",
      "Figure: Basic counts for table mtl_w1_eth_gps_delconflsat\n",
      "\n",
      "---------  ----------\n",
      " num_recs  27,282,423\n",
      "num_users         545\n",
      "---------  ----------\n"
     ]
    }
   ],
   "source": [
    "tablename = f'{city_prefix}_w1_eth_gps_delconflsat'\n",
    "sourcetable = f\"{city_prefix}_w1_eth_gps_raw_TOXIC\"\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    log(f\"Creating table {tablename} from scratch...\")\n",
    "    sql = f\"\"\"\n",
    "        SET SCHEMA '{db_schema}';\n",
    "        DROP TABLE IF EXISTS {tablename};\n",
    "        CREATE TABLE {tablename}\n",
    "        AS\n",
    "            SELECT iid, record_time, satellite_time, minlat as lat, minlon as lon\n",
    "            FROM (\n",
    "                SELECT count(1) as numrows, \n",
    "                       iid, \n",
    "                       min(record_time) as record_time, \n",
    "                       satellite_time,\n",
    "                       min(lat) as minlat, \n",
    "                       max(lat) as maxlat,\n",
    "                       min(lon) as minlon,\n",
    "                       max(lon) as maxlon\n",
    "                FROM {sourcetable}\n",
    "                GROUP BY iid, satellite_time\n",
    "                ) as count_collisions\n",
    "            WHERE numrows = 1 -- there are no duplicates at all\n",
    "               OR (minlon = maxlon AND minlat = maxlat); -- the duplicates are identical\n",
    "        CREATE UNIQUE INDEX {tablename}_idx ON {tablename} (iid, satellite_time);\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    log(f\"Done\")\n",
    "    \n",
    "    # Report basic stats on the newly created table\n",
    "    print(f\"\\nFigure: Basic counts for table {tablename}\\n\")\n",
    "    sql = f\"\"\"\n",
    "    SET SCHEMA '{db_schema}';\n",
    "    SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T23:59:48.412168Z",
     "start_time": "2020-10-13T23:58:47.785722Z"
    },
    "tags": [
     "hide_cell"
    ]
   },
   "outputs": [],
   "source": [
    "tablename = f'{city_prefix}_w1_eth_xls_delduplrec'\n",
    "# Quick block that can be run at any time to validate counts on any of the above-created tables\n",
    "with psycopg2.connect(user=db_user, host=db_host, port=db_host_port, database='interact_db') as conn:\n",
    "    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)\n",
    "    \n",
    "    # Collect the same basic stats as computed during ingest\n",
    "    sql = f\"\"\"\n",
    "    SET SCHEMA '{db_schema}';\n",
    "    SELECT SUM(num_recs) as num_recs, COUNT(1) as num_users\n",
    "        FROM (\n",
    "             SELECT COUNT(1) as num_recs\n",
    "             FROM {tablename}\n",
    "             GROUP BY iid\n",
    "           ) as records_per_user\n",
    "        \"\"\"\n",
    "    cur.execute(sql)\n",
    "    row = cur.fetchone()\n",
    "    data = [['num_recs',row['num_recs']], ['num_users',row['num_users']],]\n",
    "    print(f\"Figure: Basic counts for table {tablename}\")\n",
    "    print(tabulate(data, floatfmt=',.0f', stralign='right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here endeth the ingest."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
